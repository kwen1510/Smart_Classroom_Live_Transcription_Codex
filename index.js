import 'dotenv/config';      
import express from "express";
import { createServer } from "http";
import { Server } from "socket.io";
import { MongoClient, ServerApiVersion, ObjectId } from 'mongodb';
import { v4 as uuid } from "uuid";
import fetch from "node-fetch";
import path from "path";
import { fileURLToPath } from "url";
import { ElevenLabsClient } from "@elevenlabs/elevenlabs-js";
import multer from "multer";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

console.log("üöÄ Starting Smart Classroom Live Transcription Server...");

// Initialize ElevenLabs client
const elevenlabs = new ElevenLabsClient({
  apiKey: process.env.ELEVENLABS_KEY,
});

// Session state management
const activeSessions = new Map(); // sessionCode -> { id, code, active, interval, startTime }
const sessionTimers = new Map();  // sessionCode -> timer

// Global storage for session transcript history
const sessionTranscriptHistory = new Map();

// Utility helpers and globals
// Cache the latest emitted checklist state per session+group so we can reuse it on release
const latestChecklistState = new Map();

// Helper function to manage transcript history
function addToTranscriptHistory(sessionCode, transcript) {
  if (!sessionTranscriptHistory.has(sessionCode)) {
    sessionTranscriptHistory.set(sessionCode, []);
  }
  
  const history = sessionTranscriptHistory.get(sessionCode);
  history.push({
    transcript: transcript,
    timestamp: new Date().toISOString()
  });
  
  // Keep only the last 3 chunks for context
  if (history.length > 3) {
    history.shift();
  }
  
  console.log(`üìù Context History: Session ${sessionCode} now has ${history.length} chunks`);
}

function getContextualTranscript(sessionCode) {
  const history = sessionTranscriptHistory.get(sessionCode) || [];
  if (history.length === 0) return '';
  
  // Return combined transcript with context markers
  const contextText = history.map((chunk, index) => {
    const isLatest = index === history.length - 1;
    const chunkLabel = isLatest ? 'CURRENT CHUNK' : `PREVIOUS CHUNK ${history.length - index - 1}`;
    return `[${chunkLabel}]: ${chunk.transcript}`;
  }).join('\n\n');
  
  console.log(`üß† Context Window: Sending ${history.length} chunks for analysis`);
  return contextText;
}

function clearTranscriptHistory(sessionCode) {
  sessionTranscriptHistory.delete(sessionCode);
  console.log(`üóëÔ∏è Cleared transcript history for session: ${sessionCode}`);
}

// Helper function to get current mindmap data from database
async function getMindmapData(sessionCode) {
  try {
    const session = await db.collection("sessions").findOne({ code: sessionCode });
    if (!session) {
      console.log(`‚ö†Ô∏è Session ${sessionCode} not found for mindmap data retrieval`);
      return null;
    }
    
    return session.mindmap_data || null;
  } catch (error) {
    console.error(`‚ùå Error retrieving mindmap data for session ${sessionCode}:`, error);
    return null;
  }
}

/* ---------- 1. MongoDB ---------- */
let client;
let db;

async function connectToDatabase() {
  try {
    console.log('üì¶ Connecting to MongoDB...');
    
    // Use MONGODB_URI if provided (for Render deployment), otherwise fall back to individual components
    let uri;
    if (process.env.MONGODB_URI) {
      uri = process.env.MONGODB_URI;
    } else {
      // Fallback to individual components for local development
      const username = process.env.MONGO_DB_USERNAME || 'admin';
      const password = process.env.MONGO_DB_PASSWORD;
      if (!password) {
        throw new Error('MongoDB password not provided. Set MONGODB_URI or MONGO_DB_PASSWORD environment variable.');
      }
      uri = `mongodb+srv://${username}:${password}@cluster0.bwtbeur.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0`;
    }
    
    // Create a MongoClient with a MongoClientOptions object to set the Stable API version
    client = new MongoClient(uri, {
      serverApi: {
        version: ServerApiVersion.v1,
        strict: false,
        deprecationErrors: true,
      }
    });
    
    await client.connect();
    db = client.db("smart_classroom");
    
    console.log('üì¶ MongoDB connected');
    
    // Create indexes for better performance
    await db.collection("sessions").createIndex({ "code": 1 });
    await db.collection("sessions").createIndex({ "active": 1 });
    await db.collection("groups").createIndex({ "session_id": 1, "number": 1 });
    await db.collection("transcriptions").createIndex({ "group_id": 1, "timestamp": 1 });
    await db.collection("summaries").createIndex({ "group_id": 1, "timestamp": 1 });
    await db.collection("checkbox_sessions").createIndex({ "session_id": 1 });
    await db.collection("checkbox_criteria").createIndex({ "session_id": 1 });
    await db.collection("checkbox_results").createIndex({ "session_id": 1, "timestamp": 1 });
    await db.collection("mindmap_archives").createIndex({ "session_id": 1, "saved_at": 1 });
    await db.collection("mindmap_archives").createIndex({ "session_code": 1 });
    await db.collection("teacher_prompts").createIndex({ "title": "text", "description": "text", "content": "text", "tags": "text" });
    await db.collection("teacher_prompts").createIndex({ "category": 1 });
    await db.collection("teacher_prompts").createIndex({ "mode": 1 });
    await db.collection("teacher_prompts").createIndex({ "isPublic": 1 });
    await db.collection("teacher_prompts").createIndex({ "created_at": -1 });
    await db.collection("teacher_prompts").createIndex({ "usage_count": -1 });
    
    console.log('üìä Database indexes ready');
    
    // Seed default prompts for teachers
    await seedDefaultPrompts();
    
    // Start server after database connection
    const port = process.env.PORT || 10000;
    http.listen(port, () => {
      console.log(`üéØ Server running at http://localhost:${port}`);
    });
    
  } catch (error) {
    console.error('‚ùå MongoDB connection failed:', error);
    process.exit(1);
  }
}

// Connect to database on startup
connectToDatabase();

/* ---------- 2. Express + Socket.IO ---------- */
const app = express();
app.use(express.static(path.join(__dirname, "public")));

// Setup multer for file uploads
const upload = multer({ 
  storage: multer.memoryStorage(),
  limits: { fileSize: 10 * 1024 * 1024 } // 10MB limit
});

const http = createServer(app);
const io   = new Server(http, { cors: { origin: "*" } });

/* Serve student and admin pages */
app.get("/student", (req, res) => {
  console.log("üìö Serving student page");
  res.sendFile(path.join(__dirname, "public", "student.html"));
});
app.get("/admin", (req, res) => {
  console.log("üë®‚Äçüè´ Serving admin page");
  res.sendFile(path.join(__dirname, "public", "admin.html"));
});
app.get("/admin_static", (req, res) => {
  console.log("üë®‚Äçüè´ Serving static admin page");
  res.sendFile(path.join(__dirname, "public", "admin_static.html"));
});

/* Serve test transcription page */
app.get("/test-transcription", (req, res) => {
  res.sendFile(path.join(__dirname, "public", "test-transcription.html"));
});

/* Serve test recording page */
app.get("/test-recording", (req, res) => {
  res.sendFile(path.join(__dirname, "public", "test-recording.html"));
});

/* Serve history page */
app.get("/history", (req, res) => {
  res.sendFile(path.join(__dirname, "public", "history.html"));
});

/* Health check endpoint for Render deployment */
app.get("/health", (req, res) => {
  res.status(200).json({
    status: "healthy",
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    version: "2.0.0",
    features: ["transcription", "checkbox-mode", "mindmap-mode", "summary-mode"],
    environment: process.env.NODE_ENV || "development",
    port: process.env.PORT || 10000
  });
});

/* Test transcription API endpoint */
app.post("/api/test-transcription", upload.single('audio'), async (req, res) => {
  try {
    console.log("üß™ Test transcription request received");
    
    if (!req.file) {
      return res.status(400).json({ error: "No audio file provided" });
    }
    
    const audioBuffer = req.file.buffer;
    console.log(`üìÅ Received audio file: ${audioBuffer.length} bytes, mimetype: ${req.file.mimetype}`);
    
    // Test the transcription function
    const startTime = Date.now();
    const transcription = await transcribe(audioBuffer);
    const endTime = Date.now();
    
    const debug = {
      fileSize: audioBuffer.length,
      mimeType: req.file.mimetype,
      processingTime: `${endTime - startTime}ms`,
      timestamp: new Date().toISOString()
    };
    
    console.log(`‚úÖ Test transcription completed in ${endTime - startTime}ms`);
    
    res.json({
      success: true,
      transcription,
      debug
    });
    
  } catch (err) {
    console.error("‚ùå Test transcription error:", err);
    res.status(500).json({ 
      error: "Transcription failed", 
      details: err.message,
      stack: process.env.NODE_ENV === 'development' ? err.stack : undefined
    });
  }
});

/* Test summary API endpoint */
app.post("/api/test-summary", express.json(), async (req, res) => {
  try {
    console.log("üß™ Test summary request received");
    
    const { text, customPrompt } = req.body;
    if (!text) {
      return res.status(400).json({ error: "No text provided for summarization" });
    }
    
    console.log(`üìù Received text for summarization (${text.length} characters)`);
    
    // Test the summary function with custom prompt
    const startTime = Date.now();
    const summary = await summarise(text, customPrompt);
    const endTime = Date.now();
    
    const debug = {
      textLength: text.length,
      processingTime: `${endTime - startTime}ms`,
      timestamp: new Date().toISOString(),
      promptUsed: customPrompt || "default"
    };
    
    console.log(`‚úÖ Test summary completed in ${endTime - startTime}ms`);
    
    res.json({
      success: true,
      summary,
      debug
    });
    
  } catch (err) {
    console.error("‚ùå Test summary error:", err);
    res.status(500).json({ 
      error: "Summary failed", 
      details: err.message,
      stack: process.env.NODE_ENV === 'development' ? err.stack : undefined
    });
  }
});

/* Session prompt management endpoints */
app.post("/api/session/:code/prompt", express.json(), async (req, res) => {
  try {
    const { code } = req.params;
    const { prompt } = req.body;
    
    if (!prompt || !prompt.trim()) {
      return res.status(400).json({ error: "Prompt is required" });
    }
    
    // Get session ID
    let session = await db.collection("sessions").findOne({ code: code });
    if (!session) {
      // Session might not be persisted yet - create a placeholder record
      const mem = activeSessions.get(code);
      if (!mem) {
        return res.status(404).json({ error: "Session not found" });
      }

      const newId = uuid();
      await db.collection("sessions").insertOne({
        _id: newId,
        code: code,
        interval_ms: mem.interval || 30000,
        created_at: mem.created_at || Date.now(),
        active: mem.active || false,
        start_time: mem.startTime || null,
        end_time: null,
        total_duration_seconds: null
      });
      session = { _id: newId };
    }
    
    // Do NOT cleanup transcripts/summaries on prompt save
    
    // Save prompt for this session
    await db.collection("session_prompts").findOneAndUpdate(
      { session_id: session._id },
      { $set: { prompt: prompt.trim(), updated_at: Date.now() } },
      { upsert: true }
    );

    // Also cache the current prompt in memory so subsequent summaries use it immediately
    const mem = activeSessions.get(code);
    if (mem) {
      activeSessions.set(code, { ...mem, customPrompt: prompt.trim() });
    }
    
    console.log(`üíæ Saved custom prompt for session ${code}`);
    res.json({ success: true, message: "Prompt saved successfully" });
    
  } catch (err) {
    console.error("‚ùå Failed to save prompt:", err);
    res.status(500).json({ error: "Failed to save prompt" });
  }
});

app.get("/api/session/:code/prompt", async (req, res) => {
  try {
    const { code } = req.params;
    
    // Get session ID
    const session = await db.collection("sessions").findOne({ code: code });
    if (!session) {
      return res.json({ prompt: null, message: "No custom prompt set for this session" });
    }
    
    // Get prompt for this session
    const promptData = await db.collection("session_prompts").findOne({ session_id: session._id });
    
    if (promptData) {
      res.json({ 
        prompt: promptData.prompt,
        updatedAt: promptData.updated_at
      });
    } else {
      res.json({ 
        prompt: null,
        message: "No custom prompt set for this session"
      });
    }
    
  } catch (err) {
    console.error("‚ùå Failed to load prompt:", err);
    res.status(500).json({ error: "Failed to load prompt" });
  }
});

/* Prompt library management */
app.get("/api/prompt-library", async (req, res) => {
  try {
    const prompts = await db
      .collection("prompt_library")
      .find({})
      .sort({ name: 1 })
      .toArray();
    res.json(prompts);
  } catch (err) {
    console.error("‚ùå Failed to load prompt library:", err);
    res.status(500).json({ error: "Failed to load prompt library" });
  }
});

app.post("/api/prompt-library", express.json(), async (req, res) => {
  try {
    const { name, text } = req.body;
    if (!name || !text) {
      return res.status(400).json({ error: "Name and text are required" });
    }
    const result = await db
      .collection("prompt_library")
      .insertOne({ name: name.trim(), text: text.trim() });
    res.json({ _id: result.insertedId, name: name.trim(), text: text.trim() });
  } catch (err) {
    console.error("‚ùå Failed to save prompt to library:", err);
    res.status(500).json({ error: "Failed to save prompt" });
  }
});

app.put("/api/prompt-library/:id", express.json(), async (req, res) => {
  try {
    const { id } = req.params;
    const { name, text } = req.body;
    if (!name && !text) {
      return res.status(400).json({ error: "Nothing to update" });
    }
    const update = {};
    if (name) update.name = name.trim();
    if (text) update.text = text.trim();
    await db
      .collection("prompt_library")
      .updateOne({ _id: new ObjectId(id) }, { $set: update });
    res.json({ success: true });
  } catch (err) {
    console.error("‚ùå Failed to update prompt:", err);
    res.status(500).json({ error: "Failed to update prompt" });
  }
});

app.delete("/api/prompt-library/:id", async (req, res) => {
  try {
    const { id } = req.params;
    await db.collection("prompt_library").deleteOne({ _id: new ObjectId(id) });
    res.json({ success: true });
  } catch (err) {
    console.error("‚ùå Failed to delete prompt:", err);
    res.status(500).json({ error: "Failed to delete prompt" });
  }
});

/* Admin API: create new session */
app.get("/api/new-session", async (req, res) => {
  try {
    const id = uuid();
    const code = req.query.code || Math.floor(100000 + Math.random() * 900000).toString();
    const interval = Number(req.query.interval) || 30000;
    
    // Clear any existing session with same code (unlikely but safe)
    activeSessions.delete(code);
    
    // Store session in memory only - no database persistence until recording starts
    activeSessions.set(code, {
      id,
      code,
      active: false,
      interval,
      startTime: null,
      created_at: Date.now(),
      persisted: false // Flag to track if saved to database
    });
    
    console.log(`üÜï New session created in memory: Code=${code}, Interval=${interval}ms (memory only)`);
    res.json({ code, interval });
  } catch (err) {
    console.error("‚ùå Failed to create session:", err);
    res.status(500).json({ error: "Failed to create session" });
  }
});

/* Get session status */
app.get("/api/session/:code/status", async (req, res) => {
  try {
    const code = req.params.code;
    const sessionState = activeSessions.get(code);
    
    if (!sessionState) {
      return res.status(404).json({ error: "Session not found" });
    }
    
    console.log(`üìã Session ${code} found in memory`);
    res.json(sessionState);
  } catch (err) {
    console.error("‚ùå Failed to get session status:", err);
    res.status(500).json({ error: "Failed to get session status" });
  }
});

/* Admin API: start/stop session */
app.post("/api/session/:code/start", express.json(), async (req, res) => {
  try {
    const { interval } = req.body;
    const code = req.params.code;
    const startTime = Date.now();
    
    // Get session from memory
    const sessionState = activeSessions.get(code);
    if (!sessionState) {
      return res.status(404).json({ error: "Session not found in memory" });
    }
    
    // Persist to database when recording actually starts (first time only)
    if (!sessionState.persisted) {
      // Check if session already exists in database (in case of server restart)
      const existingSession = await db.collection("sessions").findOne({ code: code });
      
      if (existingSession) {
        // Session exists in database, just update it
        await db.collection("sessions").updateOne(
          { code: code },
          { $set: { 
            active: true, 
            interval_ms: interval || 30000,
            start_time: startTime,
            end_time: null,
            total_duration_seconds: null
          } }
        );
        
        // Update the session state with the existing database ID
        sessionState.id = existingSession._id;
        sessionState.persisted = true;
        console.log(`üîÑ Session ${code} already exists in database, updated with ID: ${existingSession._id}`);
      } else {
        // Generate a new unique ID for database insertion
        const dbSessionId = uuid();
        
        await db.collection("sessions").insertOne({
          _id: dbSessionId,
          code: code,
          interval_ms: interval || 30000,
          created_at: sessionState.created_at,
          active: true,
          start_time: startTime,
          end_time: null,
          total_duration_seconds: null
        });
        
        // Update the session state with the database ID
        sessionState.id = dbSessionId;
        sessionState.persisted = true;
        console.log(`üíæ Session ${code} persisted to database on first start with ID: ${dbSessionId}`);
      }
    } else {
      // Update existing database record
      await db.collection("sessions").updateOne(
        { code: code },
        { $set: { 
          active: true, 
          interval_ms: interval || 30000,
          start_time: startTime,
          end_time: null,
          total_duration_seconds: null
        } }
      );
      console.log(`üîÑ Session ${code} updated in database`);
    }
    
    // Update memory state
    sessionState.active = true;
    sessionState.interval = interval || 30000;
    sessionState.startTime = startTime;

    // Notify all clients to reset their local state before recording starts
    io.to(code).emit("session_reset");

    io.to(code).emit("record_now", interval || 30000);

    // Reliability: continual retries until explicit client ack (recording_started) or timeout
    const mem = activeSessions.get(code);
    if (mem) {
      if (!mem.groups) mem.groups = new Map();
      // Configure retry scheduler (every 4s, up to 30s)
      if (mem.startRetryInterval) clearInterval(mem.startRetryInterval);
      mem.startRetryUntil = Date.now() + 30000;
      mem.active = true;
      mem.startRetryInterval = setInterval(() => {
        try {
          const current = activeSessions.get(code);
          if (!current || !current.groups || !current.active) {
            clearInterval(mem.startRetryInterval);
            return;
          }
          const pending = [];
          current.groups.forEach((state, grp) => {
            if (state?.joined && !state?.recording) pending.push(grp);
          });
          if (pending.length === 0 || Date.now() > current.startRetryUntil) {
            clearInterval(current.startRetryInterval);
            current.startRetryInterval = null;
            activeSessions.set(code, current);
            if (pending.length === 0) {
              console.log("‚úÖ All groups acknowledged recording start");
            } else {
              console.log(`‚è±Ô∏è Retry window ended. Pending groups without ack: [${pending.join(', ')}]`);
            }
            return;
          }
          console.log(`üîÑ Re-emitting record_now to pending groups: [${pending.join(', ')}]`);
          pending.forEach(grp => io.to(`${code}-${grp}`).emit("record_now", interval || 30000));
        } catch (e) {
          console.warn("‚ö†Ô∏è record_now scheduler error:", e.message);
        }
      }, 4000);
      activeSessions.set(code, mem);
    }
    
    console.log(`‚ñ∂Ô∏è  Session ${code} started recording (interval: ${interval || 30000}ms)`);
    res.json({ ok: true });
  } catch (err) {
    console.error("‚ùå Failed to start session:", err);
    res.status(500).json({ error: "Failed to start session" });
  }
});

app.post("/api/session/:code/stop", async (req, res) => {
  try {
    const code = req.params.code;
    const endTime = Date.now();
    
    // Get session from memory
    const sessionState = activeSessions.get(code);
    if (!sessionState) {
      return res.status(404).json({ error: "Session not found in memory" });
    }
    
    // Only update database if session was persisted (i.e., recording was started)
    if (sessionState.persisted) {
      // Calculate total duration in seconds
      const totalDurationSeconds = sessionState.startTime ? 
        Math.floor((endTime - sessionState.startTime) / 1000) : 0;
      
      await db.collection("sessions").updateOne(
        { code: code },
        { $set: { 
          active: false,
          end_time: endTime,
          total_duration_seconds: totalDurationSeconds
        } }
      );
      
      console.log(`üíæ Session ${code} stopped and saved to database (duration: ${totalDurationSeconds}s)`);
    } else {
      console.log(`‚èπÔ∏è  Session ${code} stopped (was never persisted to database)`);
    }
    
    // Update memory state
    sessionState.active = false;
    sessionState.startTime = null;
    if (sessionState.startRetryInterval) {
      clearInterval(sessionState.startRetryInterval);
      sessionState.startRetryInterval = null;
    }
    
    io.to(code).emit("stop_recording");
    
    console.log(`‚èπÔ∏è  Session ${code} stopped recording`);
    res.json({ ok: true });
  } catch (err) {
    console.error("‚ùå Failed to stop session:", err);
    res.status(500).json({ error: "Failed to stop session" });
  }
});

/* Admin API: get transcripts for a specific group */
app.get("/api/transcripts/:code/:number", async (req, res) => {
  try {
    const { code, number } = req.params;
    console.log(`üìù Fetching transcripts for session ${code}, group ${number}`);
    
    // Get session and group IDs
    const session = await db.collection("sessions").findOne({ code: code });
    if (!session) {
      return res.status(404).json({ error: "Session not found" });
    }
    
    const group = await db.collection("groups").findOne({ session_id: session._id, number: parseInt(number) });
    if (!group) {
      return res.status(404).json({ error: "Group not found" });
    }
    
    // Get all transcripts for this group
    const transcripts = await db.collection("transcripts").find({ group_id: group._id }).sort({ created_at: -1 }).limit(50).toArray();
    
    // Get the latest summary
    const summary = await db.collection("summaries").findOne({ group_id: group._id });
    
    // Get some stats
    const stats = await db.collection("transcripts").aggregate([
      { $match: { group_id: group._id } },
      {
        $group: {
          _id: null,
          total_segments: { $sum: 1 },
          total_words: { $sum: "$word_count" },
          total_duration: { $sum: "$duration_seconds" },
          last_update: { $max: "$created_at" }
        }
      }
    ]).toArray();
    
    res.json({
      transcripts: await Promise.all(transcripts.map(async t => ({
        ...t,
        created_at: new Date(t.created_at).toISOString()
      }))),
      summary: summary || { text: "No summary available", updated_at: null },
      stats: stats[0] || {
        totalSegments: 0,
        totalWords: 0,
        totalDuration: 0,
        lastUpdate: null
      }
    });
    
  } catch (err) {
    console.error("‚ùå Failed to fetch transcripts:", err);
    res.status(500).json({ error: "Failed to fetch transcripts" });
  }
});

/* Admin API: get historical data */
app.get("/api/history", async (req, res) => {
  try {
    const { 
      sessionCode, 
      startDate, 
      endDate, 
      limit = 50, 
      offset = 0,
      includeTranscripts = 'true',
      includeSummaries = 'true'
    } = req.query;
    
    console.log(`üìä Fetching historical data with filters:`, { sessionCode, startDate, endDate, limit, offset });
    
    let sessionFilter = "";
    let params = [];
    
    if (sessionCode) {
      sessionFilter = " AND s.code = ?";
      params.push(sessionCode);
    }
    
    if (startDate) {
      sessionFilter += " AND s.created_at >= ?";
      params.push(new Date(startDate).getTime());
    }
    
    if (endDate) {
      sessionFilter += " AND s.created_at <= ?";
      params.push(new Date(endDate).getTime());
    }
    
    // Get sessions with basic info
    const sessions = await db.collection("sessions").find({}).sort({ created_at: -1 }).skip(parseInt(offset)).limit(parseInt(limit)).toArray();
    
    const result = {
      sessions: await Promise.all(sessions.map(async s => {
        // Calculate current duration for active sessions
        let currentDuration = s.total_duration_seconds || 0;
        if (s.active && s.start_time) {
          currentDuration = Math.floor((Date.now() - s.start_time) / 1000);
        }
        
        return {
          ...s,
          created_at: new Date(s.created_at).toISOString(),
          interval_seconds: s.interval_ms / 1000,
          current_duration_seconds: currentDuration,
          groups: []
        };
      })),
      pagination: {
        limit: parseInt(limit),
        offset: parseInt(offset),
        hasMore: sessions.length === parseInt(limit)
      }
    };
    
    // For each session, get detailed group data if requested
    if (includeTranscripts === 'true' || includeSummaries === 'true') {
      for (const session of result.sessions) {
        // Get groups for this session
        const groups = await db.collection("groups").find({ session_id: session._id }).sort({ number: 1 }).toArray();
        
        for (const group of groups) {
          const groupData = {
            number: group.number,
            transcripts: [],
            summary: null,
            stats: {
              totalSegments: 0,
              totalWords: 0,
              totalDuration: 0
            }
          };
          
          if (includeTranscripts === 'true') {
            // Get transcripts for this group
            groupData.transcripts = await db.collection("transcripts").find({ group_id: group._id }).sort({ created_at: 1 }).toArray();
            
            // Calculate stats
            groupData.stats = {
              totalSegments: groupData.transcripts.length,
              totalWords: groupData.transcripts.reduce((sum, t) => sum + (t.word_count || 0), 0),
              totalDuration: groupData.transcripts.reduce((sum, t) => sum + (t.duration_seconds || 0), 0)
            };
          }
          
          if (includeSummaries === 'true') {
            // Get summary for this group
            const summary = await db.collection("summaries").findOne({ group_id: group._id });
            
            if (summary) {
              groupData.summary = {
                text: summary.text,
                updated_at: new Date(summary.updated_at).toISOString()
              };
            }
          }
          
          session.groups.push(groupData);
        }
      }
    }
    
    // After all groups are pushed to session.groups in /api/history:
    for (const session of result.sessions) {
      session.group_count = session.groups.length;
      session.total_transcripts = session.groups.reduce((sum, g) => sum + (g.stats?.totalSegments || 0), 0);
      session.total_words = session.groups.reduce((sum, g) => sum + (g.stats?.totalWords || 0), 0);
      // Use actual session duration (current for active sessions, total for completed)
      session.total_duration = session.current_duration_seconds || 0;
    }
    
    res.json(result);
    
  } catch (err) {
    console.error("‚ùå Failed to fetch historical data:", err);
    res.status(500).json({ error: "Failed to fetch historical data" });
  }
});

/* Admin API: get specific session details */
app.get("/api/history/session/:code", async (req, res) => {
  try {
    const { code } = req.params;
    console.log(`üìã Fetching detailed data for session: ${code}`);
    
    // Get session info
    const session = await db.collection("sessions").findOne({ code: code });
    
    if (!session) {
      return res.status(404).json({ error: "Session not found" });
    }
    
    // Get all groups for this session
    const groups = await db.collection("groups").find({ session_id: session._id }).sort({ number: 1 }).toArray();
    
    const result = {
      session: {
        ...session,
        created_at: new Date(session.created_at).toISOString(),
        interval_seconds: session.interval_ms / 1000
      },
      groups: []
    };
    
    for (const group of groups) {
      // Get all transcripts
      const transcripts = await db.collection("transcripts").find({ group_id: group._id }).sort({ created_at: 1 }).toArray();
      
      // Get summary
      const summary = await db.collection("summaries").findOne({ group_id: group._id });
      
      const groupData = {
        number: group.number,
        transcripts: await Promise.all(transcripts.map(async t => ({
          ...t,
          created_at: new Date(t.created_at).toISOString()
        }))),
        summary: summary ? {
          text: summary.text,
          updated_at: new Date(summary.updated_at).toISOString()
        } : null,
        stats: {
          totalSegments: transcripts.length,
          totalWords: transcripts.reduce((sum, t) => sum + (t.word_count || 0), 0),
          totalDuration: transcripts.reduce((sum, t) => sum + (t.duration_seconds || 0), 0),
          firstTranscript: transcripts.length > 0 ? new Date(transcripts[0].created_at).toISOString() : null,
          lastTranscript: transcripts.length > 0 ? new Date(transcripts[transcripts.length - 1].created_at).toISOString() : null
        }
      };
      
      result.groups.push(groupData);
    }
    
    res.json(result);
    
  } catch (err) {
    console.error("‚ùå Failed to fetch session details:", err);
    res.status(500).json({ error: "Failed to fetch session details" });
  }
});

/* Admin API: delete multiple sessions */
app.delete("/api/history/sessions", express.json(), async (req, res) => {
  try {
    const { sessionIds } = req.body;
    
    if (!Array.isArray(sessionIds) || sessionIds.length === 0) {
      return res.status(400).json({ error: "Invalid session IDs provided" });
    }
    
    console.log(`üóëÔ∏è  Deleting ${sessionIds.length} sessions:`, sessionIds);
    
    // Get session details first for cleanup
    const sessions = await db.collection("sessions").find({ _id: { $in: sessionIds } }).toArray();
    
    if (sessions.length === 0) {
      return res.status(404).json({ error: "No sessions found to delete" });
    }
    
    // Delete related data for each session
    for (const session of sessions) {
      const groups = await db.collection("groups").find({ session_id: session._id }).toArray();
      const groupIds = groups.map(g => g._id);
      
      if (groupIds.length > 0) {
        // Delete transcripts, summaries for all groups
        await db.collection("transcripts").deleteMany({ group_id: { $in: groupIds } });
        await db.collection("summaries").deleteMany({ group_id: { $in: groupIds } });
        
        // Delete groups
        await db.collection("groups").deleteMany({ session_id: session._id });
      }
      
      // Delete session prompts
      await db.collection("session_prompts").deleteMany({ session_id: session._id });
      
      // Delete mindmap related data
      await db.collection("mindmap_sessions").deleteMany({ session_id: session._id });
      await db.collection("mindmap_nodes").deleteMany({ session_id: session._id });
      
      // Delete checkbox related data
      await db.collection("checkbox_sessions").deleteMany({ session_id: session._id });
      await db.collection("checkbox_criteria").deleteMany({ session_id: session._id });
      await db.collection("checkbox_progress").deleteMany({ session_id: session._id });
      
      // Delete session logs
      await db.collection("session_logs").deleteMany({ session_id: session._id });
      
      console.log(`üßπ Cleaned up data for session ${session.code}`);
    }
    
    // Delete the sessions themselves
    const deleteResult = await db.collection("sessions").deleteMany({ _id: { $in: sessionIds } });
    
    console.log(`‚úÖ Deleted ${deleteResult.deletedCount} sessions successfully`);
    
    res.json({ 
      success: true, 
      deletedCount: deleteResult.deletedCount,
      message: `Successfully deleted ${deleteResult.deletedCount} sessions and their related data`
    });
    
  } catch (err) {
    console.error("‚ùå Failed to delete sessions:", err);
    res.status(500).json({ error: "Failed to delete sessions" });
  }
});

/* ---------- Mindmap Mode API Endpoints ---------- */

/* Create mindmap session */
app.post("/api/mindmap/session", express.json(), async (req, res) => {
  try {
    const { sessionCode, mainTopic, interval = 30000 } = req.body;
    
    if (!sessionCode || !mainTopic) {
      return res.status(400).json({ error: "Session code and main topic required" });
    }
    
    console.log(`üß† Creating mindmap session: ${sessionCode} with topic: ${mainTopic}`);
    
    // Create or update the main session
    const sessionId = uuid();
    const now = Date.now();
    
    await db.collection("sessions").findOneAndUpdate(
      { code: sessionCode },
      {
        $set: {
          _id: sessionId,
          code: sessionCode,
          mode: "mindmap",
          main_topic: mainTopic,
          interval_ms: interval,
          created_at: now,
          active: true,
          start_time: now,
          end_time: null
        }
      },
      { upsert: true }
    );
    
    // Create mindmap session record with hierarchical structure
    await db.collection("mindmap_sessions").findOneAndUpdate(
      { session_id: sessionId },
      {
        $set: {
          _id: uuid(),
          session_id: sessionId,
          main_topic: mainTopic,
          current_mindmap: null, // Will store hierarchical data
          chat_history: [],
          created_at: now
        }
      },
      { upsert: true }
    );
    
    // Add to active sessions
    activeSessions.set(sessionCode, {
      id: sessionId,
      code: sessionCode,
      mode: "mindmap",
      active: true,
      interval: interval,
      startTime: now,
      created_at: now,
      persisted: true
    });
    
    res.json({ 
      success: true, 
      sessionId,
      message: "Mindmap session created successfully" 
    });
    
  } catch (err) {
    console.error("‚ùå Failed to create mindmap session:", err);
    res.status(500).json({ error: "Failed to create mindmap session" });
  }
});

/* Generate initial mindmap from text */
app.post("/api/mindmap/generate", express.json(), async (req, res) => {
  try {
    const { sessionCode, text } = req.body;
    
    if (!sessionCode || !text) {
      return res.status(400).json({ error: "Session code and text required" });
    }
    
    console.log(`üß† Generating initial mindmap for session: ${sessionCode}`);
    
    // Get session info
    const session = await db.collection("sessions").findOne({ code: sessionCode, mode: "mindmap" });
    if (!session) {
      return res.status(404).json({ error: "Mindmap session not found" });
    }
    
    // Generate mindmap using AI
    const mindmapData = await generateInitialMindmap(text, session.main_topic);
    
    // Store the generated mindmap
    await db.collection("mindmap_sessions").updateOne(
      { session_id: session._id },
      { 
        $set: { current_mindmap: mindmapData },
        $push: { 
          chat_history: {
            type: 'user',
            content: text,
            timestamp: Date.now()
          }
        }
      }
    );
    
    // Log the processing
    await db.collection("session_logs").insertOne({
      _id: uuid(),
      session_id: session._id,
      type: "mindmap_generated",
      content: text,
      ai_response: { action: "generate", data: mindmapData },
      created_at: Date.now()
    });
    
    res.json({
      success: true,
      data: mindmapData,
      message: "Initial mindmap generated successfully"
    });
    
  } catch (err) {
    console.error("‚ùå Failed to generate mindmap:", err);
    res.status(500).json({ error: "Failed to generate mindmap" });
  }
});

/* Expand existing mindmap with new information */
app.post("/api/mindmap/expand", express.json(), async (req, res) => {
  try {
    const { sessionCode, text } = req.body;
    
    if (!sessionCode || !text) {
      return res.status(400).json({ error: "Session code and text required" });
    }
    
    console.log(`üß† Expanding mindmap for session: ${sessionCode}`);
    
    // Get session and current mindmap
    const session = await db.collection("sessions").findOne({ code: sessionCode, mode: "mindmap" });
    if (!session) {
      return res.status(404).json({ error: "Mindmap session not found" });
    }
    
    const mindmapSession = await db.collection("mindmap_sessions").findOne({ session_id: session._id });
    if (!mindmapSession || !mindmapSession.current_mindmap) {
      return res.status(400).json({ error: "No existing mindmap found. Generate initial mindmap first." });
    }
    
    // Expand mindmap using AI
    const result = await expandMindmap(text, mindmapSession.current_mindmap, session.main_topic);
    
    // Store the updated mindmap and chat history
    await db.collection("mindmap_sessions").updateOne(
      { session_id: session._id },
      { 
        $set: { current_mindmap: result.updatedMindmap },
        $push: { 
          chat_history: {
            type: 'user',
            content: text,
            timestamp: Date.now()
          }
        }
      }
    );
    
    // Log the processing
    await db.collection("session_logs").insertOne({
      _id: uuid(),
      session_id: session._id,
      type: "mindmap_expanded",
      content: text,
      ai_response: { action: "expand", explanation: result.explanation, data: result.updatedMindmap },
      created_at: Date.now()
    });
    
    res.json({
      success: true,
      data: result.updatedMindmap,
      message: result.explanation,
      rawAiResponse: result.rawResponse // For collapsible display
    });
    
  } catch (err) {
    console.error("‚ùå Failed to expand mindmap:", err);
    res.status(500).json({ error: "Failed to expand mindmap" });
  }
});

/* Process transcript for mindmap (for recording mode) */
app.post("/api/mindmap/process", express.json(), async (req, res) => {
  try {
    const { sessionCode, transcript } = req.body;
    
    if (!sessionCode || !transcript) {
      return res.status(400).json({ error: "Session code and transcript required" });
    }
    
    console.log(`üß† Processing transcript for mindmap session: ${sessionCode}`);
    
    // Get session and current mindmap
    const session = await db.collection("sessions").findOne({ code: sessionCode, mode: "mindmap" });
    if (!session) {
      return res.status(404).json({ error: "Mindmap session not found" });
    }
    
    const mindmapSession = await db.collection("mindmap_sessions").findOne({ session_id: session._id });
    if (!mindmapSession) {
      return res.status(404).json({ error: "Mindmap session details not found" });
    }
    
    let result;
    
    // If no current mindmap, generate initial one
    if (!mindmapSession.current_mindmap) {
      console.log(`üß† No existing mindmap, generating initial one...`);
      const mindmapData = await generateInitialMindmap(transcript, session.main_topic);
      
      await db.collection("mindmap_sessions").updateOne(
        { session_id: session._id },
        { $set: { current_mindmap: mindmapData }}
      );
      
      result = {
        success: true,
        action: "generate",
        data: mindmapData,
        message: "Initial mindmap generated from transcript"
      };
    } else {
      // Expand existing mindmap
      console.log(`üß† Expanding existing mindmap...`);
      const expansion = await expandMindmap(transcript, mindmapSession.current_mindmap, session.main_topic);
      
      await db.collection("mindmap_sessions").updateOne(
        { session_id: session._id },
        { $set: { current_mindmap: expansion.updatedMindmap }}
      );
      
      result = {
        success: true,
        action: "expand", 
        data: expansion.updatedMindmap,
        message: expansion.explanation
      };
    }
    
    // Log the processing
    await db.collection("session_logs").insertOne({
      _id: uuid(),
      session_id: session._id,
      type: result.action === "generate" ? "transcript_generated" : "transcript_expanded",
      content: transcript,
      ai_response: result,
      created_at: Date.now()
    });
    
    res.json(result);
    
  } catch (err) {
    console.error("‚ùå Failed to process mindmap transcript:", err);
    res.status(500).json({ error: "Failed to process transcript" });
  }
});

/* Get mindmap data */
app.get("/api/mindmap/:sessionCode", async (req, res) => {
  try {
    const { sessionCode } = req.params;
    
    console.log(`üß† Fetching mindmap data for session: ${sessionCode}`);
    
    // Get session info
    const session = await db.collection("sessions").findOne({ code: sessionCode, mode: "mindmap" });
    if (!session) {
      return res.status(404).json({ error: "Mindmap session not found" });
    }

    // Get mindmap session details
    const mindmapSession = await db.collection("mindmap_sessions").findOne({ session_id: session._id });
    if (!mindmapSession) {
      return res.status(404).json({ error: "Mindmap session details not found" });
    }

    // Get session logs
    const logs = await db.collection("session_logs")
      .find({ session_id: session._id })
      .sort({ created_at: 1 })
      .toArray();

    res.json({
      success: true,
      data: mindmapSession.current_mindmap,
      mainTopic: mindmapSession.main_topic,
      chatHistory: mindmapSession.chat_history || [],
      logs: logs
    });
    
  } catch (err) {
    console.error("‚ùå Failed to fetch mindmap data:", err);
    res.status(500).json({ error: "Failed to fetch mindmap data" });
  }
});

/* Save mindmap session with metadata */
app.post("/api/mindmap/save", express.json(), async (req, res) => {
  try {
    const { sessionCode, mainTopic, startTime, endTime, duration, durationFormatted, 
            nodeCount, speechInputs, mindmapData, chatHistory, version, savedAt } = req.body;
    
    if (!sessionCode || !mainTopic || !mindmapData) {
      return res.status(400).json({ error: "Session code, main topic, and mindmap data required" });
    }
    
    console.log(`üß† Saving mindmap session: ${sessionCode} with metadata`);
    
    // Get session info
    const session = await db.collection("sessions").findOne({ code: sessionCode, mode: "mindmap" });
    if (!session) {
      return res.status(404).json({ error: "Mindmap session not found" });
    }

    // Create comprehensive session archive
    const sessionArchive = {
      _id: uuid(),
      session_id: session._id,
      session_code: sessionCode,
      main_topic: mainTopic,
      start_time: new Date(startTime),
      end_time: new Date(endTime),
      duration_seconds: duration,
      duration_formatted: durationFormatted,
      node_count: nodeCount,
      speech_inputs: speechInputs,
      mindmap_data: mindmapData,
      chat_history: chatHistory || [],
      version: version || "1.0",
      saved_at: new Date(savedAt),
      created_at: Date.now()
    };

    // Save to archived sessions collection
    await db.collection("mindmap_archives").insertOne(sessionArchive);

    // Update the main session with final metadata
    await db.collection("sessions").updateOne(
      { _id: session._id },
      { 
        $set: { 
          end_time: Date.now(),
          archived: true,
          final_node_count: nodeCount,
          final_duration: duration
        }
      }
    );

    // Update mindmap session with final data
    await db.collection("mindmap_sessions").updateOne(
      { session_id: session._id },
      { 
        $set: { 
          current_mindmap: mindmapData,
          chat_history: chatHistory || [],
          archived_at: Date.now(),
          final_metadata: {
            duration: duration,
            nodeCount: nodeCount,
            speechInputs: speechInputs
          }
        }
      }
    );

    res.json({
      success: true,
      archiveId: sessionArchive._id,
      message: "Session saved successfully with metadata"
    });
    
  } catch (err) {
    console.error("‚ùå Failed to save mindmap session:", err);
    res.status(500).json({ error: "Failed to save mindmap session" });
  }
});

// AI Functions for hierarchical mindmap processing
async function generateInitialMindmap(contextualText, mainTopic) {
  try {
    console.log(`üß† Mind-Map Maestro: Generating initial academic mindmap for topic: "${mainTopic}"`);
    
    const prompt = `You are **Mind-Map Maestro**, an expert cognitive cartographer who turns noisy classroom transcripts into precise, multilevel mind-maps.

RULES ‚Äì Follow them exactly:
1. **Noise filter** ‚Äì Skip filler words, greetings, jokes, tangents, repetitions, false starts, teacher directions, background noise descriptions, and anything that does not advance the topic "${mainTopic}". Expect ~50% of text to be noise.

2. **Signal detection** ‚Äì Keep high-value content words (nouns, verbs, adjectives) related to "${mainTopic}". Preserve exact wording for technical terms and proper nouns; paraphrase utilities as needed.

3. **Context awareness** ‚Äì You may receive multiple chunks of transcript with labels like [CURRENT CHUNK] and [PREVIOUS CHUNK]. Use ALL chunks for context, but focus primarily on extracting academic content from the CURRENT CHUNK while using previous chunks for understanding continuity.

4. **Hierarchy** ‚Äì Classify each new idea as:
   ‚Ä¢ \`main\`    (direct point supporting "${mainTopic}")
   ‚Ä¢ \`sub\`     (detail under a main point)  
   ‚Ä¢ \`example\` (concrete illustration, anecdote, data)
   Depth must not exceed 3 levels.

5. **Output strictly JSON** ‚Äì No markdown, comments, or extra text‚Äîonly a valid JSON object.

6. **Topic preservation** ‚Äì The root topic MUST be exactly "${mainTopic}". Never change this.

TOPIC: ${mainTopic}

CONTEXTUAL TRANSCRIPT:
<<<
${contextualText}
>>>

If the transcript contains NO meaningful academic content related to "${mainTopic}" (only noise/filler), return:
{"topic": "${mainTopic}", "version": "${new Date().toISOString()}", "nodes": [], "message": "No academic content detected"}

Otherwise, create a structured mindmap:
{
  "topic": "${mainTopic}",
  "version": "${new Date().toISOString()}",
  "nodes": [
    {
      "id": "uuid-here",
      "parent_id": null,
      "label": "Main concept related to ${mainTopic}",
      "type": "main"
    },
    {
      "id": "uuid-here", 
      "parent_id": "parent-uuid",
      "label": "Supporting detail",
      "type": "sub"
    },
    {
      "id": "uuid-here",
      "parent_id": "parent-uuid", 
      "label": "Specific example",
      "type": "example"
    }
  ]
}

Generate proper UUIDs for each node. Return ONLY the JSON object.`;

    const body = {
      model: "claude-sonnet-4-20250514", // Using Claude Sonnet 4 as requested
      max_tokens: 2000, // Increased for comprehensive prompt and detailed analysis
      temperature: 0, // Set to 0 for maximum consistency
      messages: [{
        role: "user",
        content: prompt
      }]
    };

    const res = await fetch("https://api.anthropic.com/v1/messages", {
      method: "POST",
      headers: {
        "x-api-key": process.env.ANTHROPIC_API_KEY || process.env.ANTHROPIC_KEY,
        "anthropic-version": "2023-06-01",
        "content-type": "application/json"
      },
      body: JSON.stringify(body)
    });

    if (!res.ok) {
      console.error(`‚ùå Mind-Map Maestro API error: ${res.status} ${res.statusText}`);
      throw new Error("AI API error");
    }

    const response = await res.json();
    const responseText = response.content[0].text;
    
    // Try to parse JSON
    try {
      const result = JSON.parse(responseText);
      
      // Check if no academic content was found
      if (result.nodes && result.nodes.length === 0) {
        console.log("‚ö†Ô∏è Mind-Map Maestro: No meaningful academic content detected");
        return null;
      }
      
      // Convert to our existing format for compatibility
      const convertedResult = convertMaestroToLegacy(result, mainTopic);
      return convertedResult;
      
    } catch (parseError) {
      // Try to extract JSON from response
      const jsonMatch = responseText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const result = JSON.parse(jsonMatch[0]);
        if (result.nodes && result.nodes.length === 0) {
          return null;
        }
        const convertedResult = convertMaestroToLegacy(result, mainTopic);
        return convertedResult;
      }
      throw new Error('Could not parse mindmap data from Mind-Map Maestro');
    }
    
  } catch (error) {
    console.error("‚ùå Failed to generate Mind-Map Maestro mindmap:", error);
    throw error;
  }
}

// Convert Mind-Map Maestro format to our legacy hierarchical format
function convertMaestroToLegacy(maestroData, mainTopic) {
  const legacy = {
    name: mainTopic,
    children: []
  };
  
  // Group nodes by parent_id
  const nodeMap = {};
  const rootNodes = [];
  
  maestroData.nodes.forEach(node => {
    nodeMap[node.id] = {
      name: node.label,
      children: [],
      type: node.type,
      id: node.id
    };
    
    if (node.parent_id === null) {
      rootNodes.push(nodeMap[node.id]);
    }
  });
  
  // Build hierarchy
  maestroData.nodes.forEach(node => {
    if (node.parent_id !== null && nodeMap[node.parent_id]) {
      nodeMap[node.parent_id].children.push(nodeMap[node.id]);
    }
  });
  
  // Add root nodes as children of main topic
  legacy.children = rootNodes;
  
  console.log(`‚úÖ Mind-Map Maestro: Converted ${maestroData.nodes.length} nodes to legacy format`);
  return legacy;
}

async function expandMindmap(contextualText, currentMindmap, mainTopic) {
  try {
    console.log(`üß† Mind-Map Maestro: Analyzing contextual content for mindmap expansion of topic: "${mainTopic}"`);
    
    // Convert current mindmap to Maestro format for processing
    const currentMaestroFormat = convertLegacyToMaestro(currentMindmap, mainTopic);
    
    const prompt = `You are **Mind-Map Maestro**, an expert cognitive cartographer who turns noisy classroom transcripts into precise, multilevel mind-maps.

RULES ‚Äì Follow them exactly:
1. **Noise filter** ‚Äì Skip filler words, greetings, jokes, tangents, repetitions, false starts, teacher directions, background noise descriptions, and anything that does not advance the topic "${mainTopic}". Expect ~50% of text to be noise.

2. **Signal detection** ‚Äì Keep high-value content words (nouns, verbs, adjectives) related to "${mainTopic}". Preserve exact wording for technical terms and proper nouns; paraphrase utilities as needed.

3. **Context awareness** ‚Äì You will receive multiple chunks of transcript with labels like [CURRENT CHUNK] and [PREVIOUS CHUNK]. Use ALL chunks for context and continuity, but focus primarily on extracting NEW academic content from the CURRENT CHUNK.

4. **Hierarchy** ‚Äì Classify each new idea as:
   ‚Ä¢ \`main\`    (direct point supporting "${mainTopic}")
   ‚Ä¢ \`sub\`     (detail under a main point)  
   ‚Ä¢ \`example\` (concrete illustration, anecdote, data)
   Depth must not exceed 3 levels.

5. **Incremental build** ‚Äì CRITICAL: Never delete or modify existing nodes; only append NEW nodes. The existing mindmap represents previous conversation context. Build upon it naturally, don't disrupt it. Avoid duplicates by checking against existing content.

6. **Output strictly JSON** ‚Äì No markdown, comments, or extra text‚Äîonly a valid JSON object.

7. **Topic preservation** ‚Äì The root topic MUST remain exactly "${mainTopic}".

TOPIC: ${mainTopic}

CURRENT MINDMAP:
<<<
${JSON.stringify(currentMaestroFormat, null, 2)}
>>>

CONTEXTUAL TRANSCRIPT:
<<<
${contextualText}
>>>

Task: Using the contextual transcript (focusing on CURRENT CHUNK), append ONLY NEW nodes that build upon the existing mindmap. If the current chunk contains no NEW meaningful academic content related to "${mainTopic}", return the unchanged mindmap with action "ignore".

IMPORTANT: Preserve ALL existing nodes. Only ADD new ones that represent genuinely new information not already covered.

Return format:
{
  "action": "ignore|expand",
  "topic": "${mainTopic}",
  "version": "${new Date().toISOString()}",
  "nodes": [/* ALL existing nodes PLUS any new ones */],
  "explanation": "Brief explanation of what was added or why ignored"
}

Generate proper UUIDs for any new nodes. Return ONLY the JSON object.`;

    const body = {
      model: "claude-sonnet-4-20250514", // Using Claude Sonnet 4 as requested
      max_tokens: 2000, // Increased for comprehensive prompt and detailed analysis
      temperature: 0, // Set to 0 for maximum consistency
      messages: [{
        role: "user",
        content: prompt
      }]
    };

    const res = await fetch("https://api.anthropic.com/v1/messages", {
      method: "POST",
      headers: {
        "x-api-key": process.env.ANTHROPIC_API_KEY || process.env.ANTHROPIC_KEY,
        "anthropic-version": "2023-06-01",
        "content-type": "application/json"
      },
      body: JSON.stringify(body)
    });

    if (!res.ok) {
      console.error(`‚ùå Mind-Map Maestro expansion API error: ${res.status} ${res.statusText}`);
      throw new Error("AI API error");
    }

    const response = await res.json();
    const responseText = response.content[0].text;
    
    // Try to parse JSON
    let result;
    try {
      result = JSON.parse(responseText);
    } catch (parseError) {
      // Try to extract JSON from response
      const jsonMatch = responseText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        result = JSON.parse(jsonMatch[0]);
      } else {
        throw new Error('Could not parse mindmap expansion data from Mind-Map Maestro');
      }
    }

    // Handle ignore action
    if (result.action === "ignore") {
      console.log("‚ö†Ô∏è Mind-Map Maestro: Content filtered out as non-academic");
      return {
        updatedMindmap: currentMindmap, // Return unchanged mindmap
        explanation: result.explanation || 'Content filtered out: no academic value',
        rawResponse: responseText,
        filtered: true
      };
    }

    // Convert result back to legacy format
    const updatedLegacyFormat = convertMaestroToLegacy(result, mainTopic);

    console.log(`‚úÖ Mind-Map Maestro: Expansion processed with ${result.nodes.length} total nodes`);

    return {
      updatedMindmap: updatedLegacyFormat,
      explanation: result.explanation || 'Academic mindmap updated successfully',
      rawResponse: responseText,
      filtered: false
    };
    
  } catch (error) {
    console.error("‚ùå Failed to expand Mind-Map Maestro mindmap:", error);
    throw error;
  }
}

// Convert legacy hierarchical format to Mind-Map Maestro format
function convertLegacyToMaestro(legacyData, mainTopic) {
  const maestro = {
    topic: mainTopic,
    version: new Date().toISOString(),
    nodes: []
  };
  
  let nodeCounter = 0;
  
  function addNode(node, parentId = null, depth = 0) {
    const nodeId = `node-${nodeCounter++}`;
    let nodeType = 'main';
    
    if (depth === 1) nodeType = 'main';
    else if (depth === 2) nodeType = 'sub';
    else if (depth >= 3) nodeType = 'example';
    
    // Don't add the root node itself, only its children
    if (node.name !== mainTopic) {
      maestro.nodes.push({
        id: nodeId,
        parent_id: parentId,
        label: node.name,
        type: nodeType
      });
    }
    
    // Process children
    if (node.children && node.children.length > 0) {
      node.children.forEach(child => {
        addNode(child, node.name === mainTopic ? null : nodeId, depth + 1);
      });
    }
  }
  
  addNode(legacyData);
  return maestro;
}

/* ---------- Checkbox Mode API Endpoints ---------- */

/* Cleanup session data */
app.post("/api/cleanup/:sessionCode", async (req, res) => {
  try {
    const { sessionCode } = req.params;
    await cleanupOldSessionData(sessionCode);
    res.json({ success: true, message: `Session ${sessionCode} cleaned up` });
  } catch (err) {
    console.error(`‚ùå Cleanup API error:`, err);
    res.status(500).json({ error: "Cleanup failed" });
  }
});

/* Create checkbox session */
app.post("/api/checkbox/session", express.json(), async (req, res) => {
  try {
    const { sessionCode, criteria, scenario, interval, strictness = 2 } = req.body; // Default strictness to 2 (moderate)
    
    if (!sessionCode || !criteria || criteria.length === 0) {
      return res.status(400).json({ error: "Session code and criteria required" });
    }
    
    console.log(`‚òëÔ∏è Creating checkbox session: ${sessionCode} with ${criteria.length} criteria`);
    console.log(`üìù Scenario: ${scenario ? scenario.substring(0, 100) + '...' : 'None provided'}`);
    console.log(`‚öñÔ∏è Strictness level: ${strictness} (1=Lenient, 2=Moderate, 3=Strict)`);
    
    // Check if session already exists
    let session = await db.collection("sessions").findOne({ code: sessionCode });
    
    // Clean up any old data for this session to ensure fresh start
    if (session) {
      await cleanupOldSessionData(sessionCode);
    }
    
    // Create or update session
    if (!session) {
      // Create new session
      session = {
        _id: uuid(),
        code: sessionCode,
        mode: "checkbox",
        active: false, // Stay inactive until /api/session/:code/start is called
        interval_ms: interval || 30000,
        strictness: strictness, // Store strictness level
        created_at: Date.now()
      };
      
      await db.collection("sessions").insertOne(session);
    } else {
      // Update existing session
      await db.collection("sessions").updateOne(
        { _id: session._id },
        { 
          $set: { 
            mode: "checkbox", 
            active: false, // Stay inactive until /api/session/:code/start is called
            interval_ms: interval || 30000,
            strictness: strictness, // Update strictness level
            updated_at: Date.now() 
          }
        }
      );
    }
    
    // Create checkbox session record with scenario
    await db.collection("checkbox_sessions").findOneAndUpdate(
      { session_id: session._id },
      {
        $set: {
          scenario: scenario,
          created_at: Date.now()
        }
      },
      { upsert: true }
    );
    
    // Add criteria (delete existing ones first to avoid duplicates)
    await db.collection("checkbox_criteria").deleteMany({ session_id: session._id });
    await db.collection("checkbox_progress").deleteMany({ session_id: session._id });
    
    const criteriaIds = [];
    const memCriteria = [];
    for (let index = 0; index < criteria.length; index++) {
      const criterion = criteria[index];
      const criterionId = uuid();
      await db.collection("checkbox_criteria").insertOne({
        _id: criterionId,
        session_id: session._id,
        description: criterion.description,
        rubric: criterion.rubric || '',  // Add rubric field
        weight: criterion.weight || 1,
        order_index: index,
        created_at: Date.now()
      });
      criteriaIds.push(criterionId);
      memCriteria.push({
        _id: criterionId,
        description: criterion.description,
        rubric: criterion.rubric || '',
        order_index: index
      });
      
      // Initialize progress records for each group (1-10 for now)
      // This ensures all criteria have a baseline state
      for (let groupNum = 1; groupNum <= 10; groupNum++) {
        await db.collection("checkbox_progress").insertOne({
          _id: uuid(),
          session_id: session._id,
          criteria_id: criterionId,
          group_number: groupNum,
          status: 'grey',
          completed: false,
          quote: null,
          created_at: Date.now()
        });
      }
    }
    
    // Add to/update active sessions and cache current checkbox config in memory
    const existingMem = activeSessions.get(sessionCode) || {};
    activeSessions.set(sessionCode, {
      id: session._id,
      code: sessionCode,
      mode: "checkbox",
      active: false, // Stay inactive until /api/session/:code/start is called
      interval: interval,
      startTime: null,
      created_at: existingMem.created_at || Date.now(),
      persisted: true,
      checkbox: {
        scenario: scenario || "",
        criteria: memCriteria,
        strictness
      }
    });
    
    res.json({
      success: true,
      sessionId: session._id,
      criteriaIds,
      message: "Checkbox session created successfully" 
    });
    
  } catch (err) {
    console.error("‚ùå Failed to create checkbox session:", err);
    res.status(500).json({ error: "Failed to create checkbox session" });
  }
});

/* Process transcript for checkbox */
app.post("/api/checkbox/process", express.json(), async (req, res) => {
  try {
    const { sessionCode, transcript, groupNumber = 1, criteria: clientCriteria, scenario: clientScenario } = req.body; // allow client-provided config
    
    if (!sessionCode || !transcript) {
      return res.status(400).json({ error: "Session code and transcript required" });
    }
    
    console.log(`‚òëÔ∏è Processing transcript for checkbox session: ${sessionCode}, group: ${groupNumber}`);
    
    // Get session info
    const session = await db.collection("sessions").findOne({ code: sessionCode, mode: "checkbox" });
    if (!session) {
      return res.status(404).json({ error: "Checkbox session not found" });
    }
    
    // Prefer client-provided or in-memory scenario/criteria for speed
    const mem = activeSessions.get(sessionCode);
    const strictness = session.strictness || 2;
    let scenario = clientScenario ?? mem?.checkbox?.scenario ?? "";
    let criteria = clientCriteria ?? mem?.checkbox?.criteria;

    // Fallback to DB only if not provided
    if (!criteria || criteria.length === 0) {
      criteria = await db.collection("checkbox_criteria")
        .find({ session_id: session._id })
        .sort({ order_index: 1, created_at: 1 })
        .toArray();
    }
    if (!scenario) {
      const checkboxSession = await db.collection("checkbox_sessions").findOne({ session_id: session._id });
      scenario = checkboxSession?.scenario || "";
    }

    // Normalize criteria to expected shape and drop any hardcoded/default leftovers
    criteria = (criteria || []).map((c, index) => ({
      originalIndex: typeof c.originalIndex === 'number' ? c.originalIndex : index,
      description: (c.description || '').toString(),
      rubric: (c.rubric || '').toString()
    }));
    
    if (criteria.length === 0) {
      return res.status(400).json({ error: "No criteria found for session" });
    }
    
    // Get existing progress for this group to avoid re-evaluating GREEN criteria
    const existingProgressRecords = await db.collection("checkbox_progress")
      .find({ 
        session_id: session._id,
        group_number: groupNumber 
      })
      .toArray();
    
    // Build existing progress array indexed by criteria position
    const existingProgress = [];
    criteria.forEach((c, idx) => {
      const progress = existingProgressRecords.find(p => p.criteria_id === c._id);
      if (progress) {
        existingProgress[idx] = {
          status: progress.status,
          quote: progress.quote,
          completed: progress.completed
        };
      } else {
        existingProgress[idx] = null;
      }
    });
    
    console.log(`üìã Found ${existingProgressRecords.length} existing progress records for group ${groupNumber}`);
    const greenCount = existingProgress.filter(p => p && p.status === 'green').length;
    if (greenCount > 0) {
      console.log(`üìã Preserving ${greenCount} GREEN criteria from previous evaluations`);
    }
    
    // Process the transcript with scenario context and strictness
    const result = await processCheckboxTranscript(transcript, criteria, scenario, strictness, existingProgress);
    
    // Log the processing result (persist once per round)
    await db.collection("session_logs").insertOne({
      _id: uuid(),
      session_id: session._id,
      type: "checkbox_analysis",
      content: transcript,
      ai_response: result,
      created_at: Date.now()
    });
    
    // Update progress for matched criteria
    const progressUpdates = [];
    const now = Date.now();
    
    for (const match of result.matches) {
      const criterion = criteria[match.criteria_index];
      if (criterion) {
        // Check existing progress to implement proper locking rules
        const existingProgress = await db.collection("checkbox_progress").findOne({
          session_id: session._id,
          criteria_id: criterion._id
        });
        
        // Implement locking rules:
        // 1. GREEN stays GREEN forever (locked)
        // 2. GREY has no quotes and can become RED or GREEN
        // 3. RED can become GREEN but not GREY
        let shouldUpdate = false;
        let newStatus = match.status;
        let newQuote = match.status === 'grey' ? null : match.quote; // Grey has no quotes
        
        if (!existingProgress) {
          // No existing progress - always update
          shouldUpdate = true;
        } else if (existingProgress.status === 'green') {
          // GREEN is locked - never update
          console.log(`üìã Criteria ${match.criteria_index} already GREEN (locked) with quote: "${existingProgress.quote}" - skipping update`);
          shouldUpdate = false;
        } else if (existingProgress.status === 'grey') {
          // GREY can become RED or GREEN
          if (match.status === 'red' || match.status === 'green') {
            shouldUpdate = true;
            console.log(`üìã Criteria ${match.criteria_index} upgrading from GREY to ${match.status.toUpperCase()}`);
          }
        } else if (existingProgress.status === 'red') {
          // RED can only become GREEN
          if (match.status === 'green') {
            shouldUpdate = true;
            console.log(`üìã Criteria ${match.criteria_index} upgrading from RED to GREEN`);
          } else {
            console.log(`üìã Criteria ${match.criteria_index} staying RED - cannot downgrade to ${match.status.toUpperCase()}`);
            shouldUpdate = false;
          }
        }
        
        if (shouldUpdate) {
          await db.collection("checkbox_progress").findOneAndUpdate(
            { 
              session_id: session._id,
              criteria_id: criterion._id,
              group_number: groupNumber  // Add group_number to the query
            },
            {
              $set: {
                completed: newStatus === 'green', // Only mark as completed if green
                quote: newQuote, // No quote for grey status
                status: newStatus,
                completed_at: now,
                group_number: groupNumber  // Ensure group_number is set
              }
            },
            { upsert: true }
          );
          
          // Emit using both stable DB criteria_id and display index to avoid off-by-one errors
          progressUpdates.push({
            criteriaId: match.criteria_index,
            criteriaDbId: criterion._id,
            description: criterion.description,
            completed: match.status === 'green',
            quote: match.quote,
            status: match.status
          });
          
          console.log(`üìã Checkbox update for criteria idx=${match.criteria_index} (_id=${criterion._id}): "${match.quote}" - STATUS: ${match.status}`);
        } else {
          console.log(`üìã Criteria ${match.criteria_index} already completed with quote: "${existingProgress.quote}" - skipping update`);
        }
      }
    }
    
    console.log(`üì§ Sending ${progressUpdates.length} checkbox updates to admin for group ${groupNumber}`);
    
    // Send checkbox updates to admin
    io.to(sessionCode).emit("admin_update", {
      group: groupNumber,
      latestTranscript: transcript,
      checkboxUpdates: progressUpdates,
      isActive: true
    });
    
    // NEW: Also emit full checklist state to both teachers and students
    // Get the current release state from database
    const checkboxSessionData = await db.collection("checkbox_sessions").findOne({ session_id: session._id });
    const isReleased = checkboxSessionData?.released_groups?.[groupNumber] || false;
    
    // Get all current progress for this group
    const allProgress = await db.collection("checkbox_progress").find({
      session_id: session._id,
      group_number: groupNumber
    }).toArray();
    
    // Build complete checklist state
    const checklistData = {
      groupNumber: groupNumber,
      criteria: criteria.map((c, idx) => {
        const progress = allProgress.find(p => p.criteria_id === c._id);
        return {
          id: idx, // stable index based on sorted order_index
          dbId: c._id,
          description: c.description,
          rubric: c.rubric || '',
          status: progress?.status || 'grey',
          completed: progress?.completed || false,
          quote: progress?.quote || null
        };
      }),
      scenario: checkboxSession?.scenario || "",
      timestamp: Date.now(),
      isReleased: isReleased,  // Controls student visibility
      sessionCode: sessionCode
    };
    
    console.log(`üì® Emitting checklist state to all (released: ${isReleased})`);
    
    // Emit to everyone in session
    io.to(sessionCode).emit('checklist_state', checklistData);
    io.to(`${sessionCode}-${groupNumber}`).emit('checklist_state', checklistData);
    // Cache latest state
    latestChecklistState.set(`${sessionCode}-${groupNumber}`, checklistData);
    
    res.json({
      success: true,
      matches: result.matches.length,
      reason: result.reason,
      progressUpdates: progressUpdates
    });
    
  } catch (err) {
    console.error("‚ùå Failed to process checkbox transcript:", err);
    res.status(500).json({ error: "Failed to process transcript" });
  }
});

/* Get checkbox data */
app.get("/api/checkbox/:sessionCode", async (req, res) => {
  try {
    const { sessionCode } = req.params;
    
    console.log(`‚òëÔ∏è Fetching checkbox data for session: ${sessionCode}`);
    
    // Get session info
    const session = await db.collection("sessions").findOne({ code: sessionCode, mode: "checkbox" });
    if (!session) {
      return res.status(404).json({ error: "Checkbox session not found" });
    }
    
    // Get checkbox session data (includes scenario)
    const checkboxSession = await db.collection("checkbox_sessions").findOne({ session_id: session._id });
    
    // Get criteria
    const criteria = await db.collection("checkbox_criteria")
      .find({ session_id: session._id })
      .sort({ order_index: 1, created_at: 1 })
      .toArray();
    
    // Get progress for each criterion
    const progress = await db.collection("checkbox_progress")
      .find({ session_id: session._id })
      .toArray();
    
    // Combine criteria with progress
    const criteriaWithProgress = criteria.map(criterion => {
      const prog = progress.find(p => p.criteria_id === criterion._id);
      return {
        ...criterion,
        completed: prog?.completed || false,
        confidence: prog?.confidence || 0,
        evidence: prog?.evidence || null,
        completedAt: prog?.completed_at || null
      };
    });
    
    // Get recent logs
    const logs = await db.collection("session_logs")
      .find({ session_id: session._id })
      .sort({ created_at: -1 })
      .limit(50)
      .toArray();
    
    // Calculate statistics
    const completedCount = criteriaWithProgress.filter(c => c.completed).length;
    const totalCount = criteriaWithProgress.length;
    const completionRate = totalCount > 0 ? (completedCount / totalCount) * 100 : 0;
    
    res.json({
      success: true,
      session: {
        code: sessionCode,
        createdAt: session.created_at,
        scenario: checkboxSession?.scenario || ""
      },
      criteria: criteriaWithProgress,
      stats: {
        total: totalCount,
        completed: completedCount,
        completionRate: Math.round(completionRate)
      },
      logs: logs
    });
    
  } catch (err) {
    console.error("‚ùå Failed to fetch checkbox data:", err);
    res.status(500).json({ error: "Failed to fetch checkbox data" });
  }
});

/* Get session logs */
app.get("/api/logs/:sessionCode", async (req, res) => {
  try {
    const { sessionCode } = req.params;
    const { limit = 100, type } = req.query;
    
    console.log(`üìã Fetching logs for session: ${sessionCode}`);
    
    // Get session info
    const session = await db.collection("sessions").findOne({ code: sessionCode });
    if (!session) {
      return res.status(404).json({ error: "Session not found" });
    }
    
    // Build query
    const query = { session_id: session._id };
    if (type) {
      query.type = type;
    }
    
    // Get logs
    const logs = await db.collection("session_logs")
      .find(query)
      .sort({ created_at: -1 })
      .limit(parseInt(limit))
      .toArray();
    
    res.json({
      success: true,
      logs: logs,
      session: {
        code: sessionCode,
        mode: session.mode
      }
    });
    
  } catch (err) {
    console.error("‚ùå Failed to fetch logs:", err);
    res.status(500).json({ error: "Failed to fetch logs" });
  }
});

/* ---------- Auto-summary management ---------- */
const activeSummaryTimers = new Map();

function startAutoSummary(sessionCode, intervalMs) {
  // Clear any existing timer for this session
  stopAutoSummary(sessionCode);
  
  const timer = setInterval(async () => {
    console.log(`‚è∞ Auto-generating summaries for session ${sessionCode}`);
    
    // Check if session is still active (both in memory and database)
    const sessionState = activeSessions.get(sessionCode);
    const session = await db.collection("sessions").findOne({ code: sessionCode, active: true });
    
    if (!session || !sessionState?.active) {
      console.log(`‚ö†Ô∏è  Session ${sessionCode} no longer active, stopping auto-summary`);
      stopAutoSummary(sessionCode);
      return;
    }
    
    const groups = await db.collection("groups").find({ session_id: session._id }).sort({ number: 1 }).toArray();
    console.log(`üîÑ Processing summaries for ${groups.length} groups in session ${sessionCode}`);
    
    for (const group of groups) {
      await generateSummaryForGroup(sessionCode, group.number);
    }
  }, intervalMs); // Use the same interval as recording instead of fixed 10 seconds
  
  activeSummaryTimers.set(sessionCode, timer);
  console.log(`‚è∞ Started auto-summary timer for session ${sessionCode} (every ${intervalMs}ms)`);
}

function stopAutoSummary(sessionCode) {
  const timer = activeSummaryTimers.get(sessionCode);
  if (timer) {
    clearInterval(timer);
    activeSummaryTimers.delete(sessionCode);
    console.log(`‚è∞ Stopped auto-summary timer for session ${sessionCode}`);
  }
}

// Concurrency guard for transcription
const processingGroups = new Set();

async function generateSummaryForGroup(sessionCode, groupNumber) {
  const groupKey = `${sessionCode}-${groupNumber}`;
  
  // Prevent overlapping processing for the same group
  if (processingGroups.has(groupKey)) {
    console.log(`‚è≥ Group ${groupNumber} already being processed, skipping`);
    return;
  }
  
  processingGroups.add(groupKey);
  
  try {
    console.log(`üìã Processing group ${groupNumber} in session ${sessionCode}`);
    
    // Find sockets in this group and get their audio data
    const roomName = `${sessionCode}-${groupNumber}`;
    const socketsInRoom = await io.in(roomName).fetchSockets();
    
    if (socketsInRoom.length === 0) {
      console.log(`‚ÑπÔ∏è  No active sockets in group ${groupNumber}, skipping`);
      return;
    }
    
    // Collect audio from all sockets in this group
    let hasAudio = false;
    let combinedAudio = [];
    
    for (const socket of socketsInRoom) {
      if (socket.localBuf && socket.localBuf.length > 0) {
        // For WebM containers, we should have at most one complete container per socket
        // For other formats, we might have multiple chunks
        const audioChunks = socket.localBuf.filter(chunk => chunk.data.length > 20000); // Guardrail: only process substantial chunks
        
        if (audioChunks.length > 0) {
          // For WebM, we need to handle both complete containers and partial chunks
          const baseMime = extractMime(audioChunks[0].format);
          if (baseMime === 'audio/webm') {
            // First, look for a complete WebM container
            const completeContainer = audioChunks.find(chunk => {
              const header = chunk.data.slice(0, 4).toString('hex');
              return header === '1a45dfa3' && !chunk.isPartial;
            });
            
            if (completeContainer) {
              console.log(`‚úÖ Found complete WebM container (${completeContainer.data.length} bytes) from socket ${socket.id}`);
              combinedAudio.push(completeContainer);
              hasAudio = true;
            } else {
              // Don't try to combine partial chunks - they create corrupted WebM data
              // Instead, just skip this processing cycle and wait for a complete container
              console.log(`‚è≠Ô∏è  No complete WebM container found, skipping processing (${audioChunks.length} partial chunks available)`);
              console.log(`üí° Waiting for complete WebM container with header 1a45dfa3...`);
            }
          } else {
            // For other formats, add all substantial chunks
            combinedAudio.push(...audioChunks);
            hasAudio = true;
          }
        }
        
        socket.localBuf.length = 0; // Clear buffer after processing
      }
    }
    
    if (!hasAudio) {
      console.log(`‚ÑπÔ∏è  No substantial audio data available for group ${groupNumber}, skipping`);
      return;
    }
    
    // Process each blob individually instead of concatenating
    for (const audioChunk of combinedAudio) {
      console.log(`üîÑ Processing ${audioChunk.data.length} bytes of audio data for group ${groupNumber}`);
      
      // Validate audio before sending to API
      if (audioChunk.data.length < 1000) {
        console.log(`‚ö†Ô∏è  Audio too small (${audioChunk.data.length} bytes), skipping`);
        continue;
      }
      
      // Check if audio has valid headers for common formats
      const header = audioChunk.data.slice(0, 4).toString('hex');
      const validHeaders = {
        '1a45dfa3': 'WebM',
        '52494646': 'WAV/RIFF',
        '00000020': 'MP4',
        '4f676753': 'OGG'
      };
      
      if (validHeaders[header]) {
        console.log(`‚úÖ Valid ${validHeaders[header]} header detected: ${header}`);
      } else {
        console.log(`‚ö†Ô∏è  Unknown audio header: ${header}, proceeding anyway`);
        // Log the first few bytes for debugging
        const firstBytes = audioChunk.data.slice(0, 8).toString('hex');
        console.log(`üîç First 8 bytes: ${firstBytes}`);
      }
      
      // Get transcription for this individual audio chunk
      console.log("üó£Ô∏è  Starting transcription for current chunk...");
      
      console.log(`üéµ Audio format: ${audioChunk.format}`);
      
      const transcription = await transcribe(audioChunk.data, audioChunk.format);
      
      // Only proceed if we have valid transcription
      let cleanedText = transcription.text;
      if (transcription.text && transcription.text !== "No transcription available" && transcription.text !== "Transcription failed") {
        // Transcript cleaning removed - using raw transcription
        console.log(`üìù Transcription for group ${groupNumber}:`, {
          text: cleanedText,
          duration: transcription.words.length > 0 ? 
            transcription.words[transcription.words.length - 1].end : 0,
          wordCount: transcription.words.length
        });
        
        // Save this individual transcription segment
        const session = await db.collection("sessions").findOne({ code: sessionCode });
        const group = await db.collection("groups").findOne({ session_id: session._id, number: parseInt(groupNumber) });
        
        if (group) {
          // Save the transcription segment
          const now = Date.now();
          const transcriptId = uuid();
          
          // Calculate word count and duration with fallbacks
          const wordCount = transcription.words && transcription.words.length > 0 ? 
            transcription.words.length : 
            transcription.text.split(' ').filter(w => w.trim().length > 0).length;
          
          const duration = transcription.words && transcription.words.length > 0 ? 
            transcription.words[transcription.words.length - 1].end : 
            Math.max(10, Math.min(30, transcription.text.length * 0.05)); // Estimate 0.05 seconds per character
          
          await db.collection("transcripts").insertOne({
            _id: transcriptId,
            group_id: group._id,
            text: cleanedText,
            word_count: wordCount,
            duration_seconds: duration,
            created_at: now,
            segment_number: Math.floor(now / 30000) // Update segment tracking for new interval
          });
          
          // Get all transcripts for this group to create summary of FULL conversation
          const allTranscripts = await db.collection("transcripts").find({ group_id: group._id }).sort({ created_at: 1 }).toArray();
          
          // Combine all transcripts for summary (but only transcribe current chunk)
          const fullText = allTranscripts.map(t => t.text).join(' ');
          
          // Generate summary of the entire conversation so far
          console.log("ü§ñ Generating summary of full conversation...");
          
          // Get custom prompt for this session
          // Resolve the latest prompt: prefer memory cache (if admin changed it mid-session), fall back to DB
          let customPrompt = activeSessions.get(sessionCode)?.customPrompt || null;
          if (!customPrompt && session) {
            const promptData = await db.collection("session_prompts").findOne({ session_id: session._id });
            customPrompt = promptData?.prompt || null;
          }
          
          const summary = await summarise(fullText, customPrompt);
          
          // Save/update the summary
          await db.collection("summaries").findOneAndUpdate(
            { group_id: group._id },
            { $set: { text: summary, updated_at: now } },
            { upsert: true }
          );
          
          // Send both new transcription and updated summary to clients
          io.to(roomName).emit("transcription_and_summary", {
            transcription: {
              text: cleanedText,
              words: transcription.words,
              duration: duration,
              wordCount: wordCount
            },
            summary,
            isLatestSegment: true
          });
          
          // Send update to admin console
          io.to(sessionCode).emit("admin_update", {
            group: groupNumber,
            latestTranscript: cleanedText,
            cumulativeTranscript: fullText, // Add full conversation for admin
            transcriptDuration: duration,
            transcriptWordCount: wordCount,
            summary,
            stats: {
              totalSegments: allTranscripts.length,
              totalWords: allTranscripts.reduce((sum, t) => sum + (t.word_count || 0), 0),
              totalDuration: allTranscripts.reduce((sum, t) => sum + (t.duration_seconds || 0), 0),
              lastUpdate: now
            }
          });
          
          console.log(`‚úÖ Results saved and sent for session ${sessionCode}, group ${groupNumber}`);
        }
      } else {
        console.log(`‚ö†Ô∏è  No valid transcription for group ${groupNumber}`);
      }
    }
    
  } catch (err) {
    console.error(`‚ùå Error processing group ${groupNumber}:`, err);
  } finally {
    processingGroups.delete(groupKey);
  }
}

// Helper to clean up transcript using Anthropic
async function cleanTranscriptWithAnthropic(text) {
  return summarise(
    text,
    "Clean up the following transcript for grammar, punctuation, and readability, but do not summarize or remove any content. Only return the cleaned transcript:"
  );
}

/* ---------- 3. WebSocket flow ---------- */
io.on("connection", socket => {
  console.log(`üîå New socket connection: ${socket.id}`);
  let groupId, localBuf = [], sessionCode, groupNumber;

  // Live prompt updates from admin: keep latest prompt in memory to avoid DB reads
  socket.on('prompt_update', data => {
    try {
      const { sessionCode: code, prompt } = data || {};
      if (!code || typeof prompt !== 'string') return;
      const mem = activeSessions.get(code);
      if (mem) {
        activeSessions.set(code, { ...mem, customPrompt: prompt });
      }
    } catch (e) {
      console.warn('‚ö†Ô∏è prompt_update handling error:', e.message);
    }
  });
  
  // Attach buffer to socket for auto-summary access
  socket.localBuf = localBuf;

  // Timestamp helper for logs
  function ts() { return new Date().toISOString(); }

  // Admin joins session room
  socket.on("admin_join", ({ code }) => {
    try {
      console.log(`üë®‚Äçüè´ Admin socket ${socket.id} joining session room: ${code}`);
      socket.join(code);
      console.log(`‚úÖ Admin joined session room: ${code}`);
    } catch (err) {
      console.error("‚ùå Error admin joining session room:", err);
    }
  });

  socket.on("join", async ({ code, group }) => {
    try {
      console.log(`[${ts()}] üëã Socket ${socket.id} attempting to join session ${code}, group ${group}`);
      
      // Check memory only - no database lookup
      const sessionState = activeSessions.get(code);
      
      if (!sessionState) {
        console.log(`‚ùå Session ${code} not found`);
        return socket.emit("error", "Session not found");
      }
      
      sessionCode = code;
      groupNumber = group;
      
      // Only create database entries if session has been persisted (i.e., recording started)
      if (sessionState.persisted) {
        // Session exists in database, handle group creation normally
        const sess = await db.collection("sessions").findOne({ code: code });
        if (!sess) {
          console.log(`‚ùå Session ${code} not found in database despite being marked as persisted`);
          return socket.emit("error", "Session data inconsistent");
        }
        
        const existing = await db.collection("groups").findOne({ session_id: sess._id, number: parseInt(group) });
        groupId = existing?._id ?? uuid();
        
        if (!existing) {
          await db.collection("groups").insertOne({
            _id: groupId,
            session_id: sess._id,
            number: parseInt(group)
          });
          console.log(`üìù Created new group: Session ${code}, Group ${group}, ID: ${groupId}`);
        } else {
          console.log(`üîÑ Rejoined existing group: Session ${code}, Group ${group}, ID: ${groupId}`);
        }
      } else {
        // Session not yet persisted, just create a temporary group ID
        groupId = uuid();
        console.log(`üìù Created temporary group ID for unpersisted session: ${groupId}`);
      }
      
      socket.join(code);
      socket.join(`${code}-${group}`);
      
      // Send different status based on session state
      if (sessionState.active) {
        socket.emit("joined", { code, group, status: "recording", interval: sessionState.interval || 30000 });
        console.log(`‚úÖ Socket ${socket.id} joined ACTIVE session ${code}, group ${group}`);
        // Track joined group for reliability retries
        const mem = activeSessions.get(code) || {};
        if (!mem.groups) mem.groups = new Map();
        mem.groups.set(parseInt(group), { joined: true, recording: false, lastAck: Date.now() });
        activeSessions.set(code, mem);
        // Immediate emit to this group if server is active and not yet recording
        io.to(`${code}-${parseInt(group)}`).emit("record_now", sessionState.interval || 30000);
      } else {
        socket.emit("joined", { code, group, status: "waiting", interval: sessionState.interval || 30000 });
        console.log(`‚úÖ Socket ${socket.id} joined INACTIVE session ${code}, group ${group} - waiting for start`);
        const mem = activeSessions.get(code) || {};
        if (!mem.groups) mem.groups = new Map();
        mem.groups.set(parseInt(group), { joined: true, recording: false, lastAck: Date.now() });
        activeSessions.set(code, mem);
      }
      
      // Notify admin about student joining
      socket.to(code).emit("student_joined", { group, socketId: socket.id });
      console.log(`[${ts()}] üì¢ Notified admin about student joining group ${group}`);
      
    } catch (err) {
      console.error("‚ùå Error joining session:", err);
      socket.emit("error", "Failed to join session");
    }
  });

  socket.on("student:chunk", ({ data, format }) => {
    // Note: This event is no longer used. Students now upload chunks directly via /api/transcribe-chunk
    console.log(`‚ö†Ô∏è  Received old-style chunk from ${sessionCode}, group ${groupNumber} - ignoring (use /api/transcribe-chunk instead)`);
  });

  // Handle heartbeat to keep connection alive (especially for background recording)
  socket.on("heartbeat", ({ session, group }) => {
    console.log(`[${ts()}] üíì Heartbeat from session ${session}, group ${group} (socket: ${socket.id})`);
    socket.emit("heartbeat_ack");
    // Mark group alive; if session active, also flag as recording
    const mem = activeSessions.get(session);
    if (mem) {
      if (!mem.groups) mem.groups = new Map();
      const st = mem.groups.get(parseInt(group)) || {};
      st.joined = true;
      st.lastAck = Date.now();
      if (mem.active) st.recording = true;
      mem.groups.set(parseInt(group), st);
      activeSessions.set(session, mem);
    }
  });

  // Explicit client acknowledgement when recording actually starts
  socket.on('recording_started', ({ session, group, interval }) => {
    try {
      const mem = activeSessions.get(session);
      if (!mem) return;
      if (!mem.groups) mem.groups = new Map();
      const st = mem.groups.get(parseInt(group)) || {};
      st.joined = true;
      st.recording = true;
      st.lastAck = Date.now();
      mem.groups.set(parseInt(group), st);
      activeSessions.set(session, mem);
      console.log(`‚úÖ recording_started ack from group ${group} (session ${session})`);
    } catch (e) {
      console.warn('‚ö†Ô∏è recording_started handler error:', e.message);
    }
  });

  // Handle admin heartbeat
  socket.on("admin_heartbeat", ({ sessionCode }) => {
    console.log(`[${ts()}] üíì Admin heartbeat from session ${sessionCode} (socket: ${socket.id})`);
    socket.emit("admin_heartbeat_ack");
  });

  // Optional: server-side keepalive ping back every 10s to all sockets in same room
  // This helps some proxies keep connections warm

  /* ===== DEV ONLY: Simulate disconnect test (guarded by env) ===== */
  socket.on('dev_simulate_disconnect', ({ sessionCode: code, target = 'all', group = 1, durationMs = 5000 }) => {
    if (!process.env.ALLOW_DEV_TEST) {
      console.log('üö´ dev_simulate_disconnect ignored (ALLOW_DEV_TEST not set)');
      return;
    }
    try {
      console.log(`üß™ DEV: simulate disconnect ‚Üí session ${code}, target=${target}, group=${group}, duration=${durationMs}ms`);
      const payload = { durationMs: Number(durationMs) || 5000 };
      if (target === 'all') {
        io.to(code).emit('dev_simulate_disconnect', payload);
      } else {
        io.to(`${code}-${parseInt(group)}`).emit('dev_simulate_disconnect', payload);
      }
    } catch (e) {
      console.warn('‚ö†Ô∏è dev_simulate_disconnect error:', e.message);
    }
  });
  /* ===== END DEV ONLY ===== */

  // Handle upload errors from students
  socket.on("upload_error", ({ session, group, error, chunkSize, timestamp }) => {
    console.log(`‚ùå Upload error from session ${session}, group ${group}: ${error}`);
    
    // Notify admin about the upload error
    socket.to(session).emit("upload_error", {
      group: group,
      error: error,
      chunkSize: chunkSize,
      timestamp: timestamp,
      socketId: socket.id
    });
    
    // Log error for debugging
    console.log(`üìä Upload error details: ${chunkSize} bytes, ${error}`);
  });

  socket.on("disconnect", () => {
    if (sessionCode && groupNumber) {
    console.log(`[${ts()}] üîå Socket ${socket.id} disconnected from session ${sessionCode}, group ${groupNumber}`);
      
      // Notify admin about student leaving
      socket.to(sessionCode).emit("student_left", { group: groupNumber, socketId: socket.id });
    } else {
      console.log(`üîå Socket ${socket.id} disconnected (no session/group)`);
    }
    
    // Clean up socket buffer to prevent memory leaks
    if (socket.localBuf) {
      socket.localBuf.length = 0;
      socket.localBuf = null;
    }
    
    // Remove from processing groups if it was being processed
    if (sessionCode && groupNumber) {
      const groupKey = `${sessionCode}-${groupNumber}`;
      processingGroups.delete(groupKey);
    }
  });

  // Handle student disconnection
  socket.on('disconnect', () => {
    console.log(`üîå Socket disconnected: ${socket.id}`);
    
    // Socket.IO automatically handles room cleanup when sockets disconnect
    // No manual cleanup needed for socket rooms
    // activeSessions only stores session metadata, not socket collections
  });

  // Debug helper - tell client what rooms they're in
  socket.on('get_my_rooms', () => {
    console.log(`üîç Socket ${socket.id} requested room info`);
    console.log(`üîç Socket ${socket.id} is in rooms:`, Array.from(socket.rooms));
    socket.emit('room_info', {
      socketId: socket.id,
      rooms: Array.from(socket.rooms)
    });
  });

  // Handle checklist release to students
  socket.on('release_checklist', async (data) => {
    try {
      console.log(`üì§ Teacher releasing checklist to Group ${data.groupNumber} in session ${data.sessionCode}`);
      
      const cacheKey = `${data.sessionCode}-${Number(data.groupNumber)}`;
      const cached = latestChecklistState.get(cacheKey);
      if (cached) {
        console.log(`üóÑÔ∏è Using cached checklist_state as merge source (cached ${cached.criteria?.length || 0} items)`);
      }
      
      // Get the session from database to get its _id
      const session = await db.collection("sessions").findOne({ code: data.sessionCode });
      if (!session) {
        console.error(`‚ùå Session ${data.sessionCode} not found in database`);
        return;
      }
      
      // Update the release flag in database
      await db.collection("checkbox_sessions").updateOne(
        { session_id: session._id },
        { 
          $set: { 
            [`released_groups.${data.groupNumber}`]: true,
            [`release_timestamps.${data.groupNumber}`]: Date.now()
          }
        },
        { upsert: true }
      );
      
      console.log(`‚úÖ Release flag set for group ${data.groupNumber} in session ${data.sessionCode}`);
      
      // Build authoritative checklist state from DB progress for this group
      const checkboxSession = await db.collection("checkbox_sessions").findOne({ session_id: session._id });
      const dbCriteria = await db.collection("checkbox_criteria")
        .find({ session_id: session._id })
        .sort({ order_index: 1, created_at: 1 })
        .toArray();
      const progress = await db.collection("checkbox_progress")
        .find({ session_id: session._id, group_number: Number(data.groupNumber) })
        .toArray();
      
      // Fallback: if DB has no criteria yet (race on first start), use teacher-provided payload
      const incomingCriteria = Array.isArray(data.criteria) ? data.criteria : [];
      let finalCriteria;
      if (!dbCriteria || dbCriteria.length === 0) {
        console.warn(`‚ö†Ô∏è No DB criteria found for session ${data.sessionCode}. Falling back to teacher payload with ${incomingCriteria.length} items.`);
        finalCriteria = incomingCriteria.map((c, idx) => ({
          id: Number(c.id ?? idx),
          dbId: c.dbId,
          description: c.description,
          rubric: c.rubric || '',
          status: c.status || 'grey',
          completed: c.status === 'green' ? true : Boolean(c.completed),
          quote: c.quote ?? null
        }));
      } else {
        // Build from DB first
        finalCriteria = dbCriteria.map((c, idx) => {
          const prog = progress.find(p => p.criteria_id === c._id);
          return {
            id: idx,
            dbId: c._id,
            description: c.description,
            rubric: c.rubric || '',
            status: prog?.status || 'grey',
            completed: prog?.completed || (prog?.status === 'green') || false,
            quote: prog?.quote || null
          };
        });
        // Merge in teacher payload to avoid initial all-grey if DB progress isn't there yet
        if (incomingCriteria.length > 0) {
          const byDbId = new Map(incomingCriteria.filter(x => x.dbId).map(x => [x.dbId, x]));
          const byIdx = new Map(incomingCriteria.map(x => [Number(x.id), x]));
          finalCriteria = finalCriteria.map(item => {
            const fromTeacher = (item.dbId && byDbId.get(item.dbId)) || byIdx.get(Number(item.id));
            if (!fromTeacher) return item;
            const teacherStatus = fromTeacher.status || 'grey';
            const preferTeacher = (teacherStatus === 'green') || (item.status === 'grey' && teacherStatus !== 'grey');
            if (preferTeacher) {
              return {
                ...item,
                status: teacherStatus,
                completed: teacherStatus === 'green' ? true : item.completed,
                quote: (fromTeacher.quote && fromTeacher.quote !== 'null') ? fromTeacher.quote : item.quote
              };
            }
            return item;
          });
        }
        // Merge in cached latest state to avoid blanks on first release
        if (cached && Array.isArray(cached.criteria) && cached.criteria.length > 0) {
          const cacheByIdx = new Map(cached.criteria.map(x => [Number(x.id), x]));
          finalCriteria = finalCriteria.map(item => {
            const fromCache = cacheByIdx.get(Number(item.id));
            if (!fromCache) return item;
            const cacheStatus = fromCache.status || 'grey';
            const preferCache = (cacheStatus === 'green') || (item.status === 'grey' && cacheStatus !== 'grey');
            if (preferCache) {
              return {
                ...item,
                status: cacheStatus,
                completed: cacheStatus === 'green' ? true : item.completed,
                quote: (fromCache.quote && fromCache.quote !== 'null') ? fromCache.quote : item.quote
              };
            }
            return item;
          });
        }
      }
      
      // Ensure stable ordering by numeric id
      finalCriteria = (finalCriteria || []).slice().sort((a, b) => Number(a.id) - Number(b.id));
      if (!finalCriteria || finalCriteria.length === 0) {
        // Last resort: if everything failed, use cached criteria entirely
        if (cached && Array.isArray(cached.criteria) && cached.criteria.length > 0) {
          console.warn('‚ö†Ô∏è DB and teacher payload empty, falling back to cached checklist state entirely');
          finalCriteria = cached.criteria.map(c => ({
            id: Number(c.id),
            dbId: c.dbId,
            description: c.description,
            rubric: c.rubric || '',
            status: c.status || 'grey',
            completed: Boolean(c.completed),
            quote: c.quote ?? null
          }));
        }
      }
      
      const checklistData = {
        sessionCode: data.sessionCode,
        groupNumber: Number(data.groupNumber),
        criteria: finalCriteria,
        scenario: checkboxSession?.scenario || data.scenario || "",
        timestamp: Date.now(),
        isReleased: true
      };
      
      console.log('üì§ Emitting authoritative released checklist:', {
        group: checklistData.groupNumber,
        criteriaCount: checklistData.criteria.length,
        sampleStatuses: checklistData.criteria.map(c => c.status).slice(0, 7)
      });
      
      // Emit to everyone - students will now see it because isReleased is true
      io.to(data.sessionCode).emit('checklist_state', checklistData);
      io.to(`${data.sessionCode}-${data.groupNumber}`).emit('checklist_state', checklistData);
      
      console.log(`‚úÖ Checklist released to session ${data.sessionCode} for Group ${data.groupNumber}`);
    } catch (error) {
      console.error('‚ùå Error handling checklist release:', error);
    }
  });
});

/* ---------- 4. External API helpers ---------- */
// Helper to extract base MIME type (before semicolon)
function extractMime(mime) {
  if (!mime) return 'audio/webm';
  return mime.split(';')[0].trim().toLowerCase();
}

async function transcribe(buf, format = 'audio/webm') {
  try {
    console.log(`üåê Calling ElevenLabs API for transcription (${buf.length} bytes, format: ${format})`);
    
    // Additional validation
    if (!buf || buf.length === 0) {
      console.log("‚ö†Ô∏è  Empty audio buffer provided");
      return { text: "No audio data available", words: [] };
    }
    
    if (buf.length < 1000) {
      console.log(`‚ö†Ô∏è  Audio buffer too small (${buf.length} bytes) for transcription`);
      return { text: "Audio too short for transcription", words: [] };
    }
    
    // Create FormData for the API call
    const FormData = (await import('form-data')).default;
    const formData = new FormData();
    
    // Extract base MIME type and map formats correctly
    const baseMime = extractMime(format);
    let audioMime = baseMime;
    let filename = 'audio.webm';
    
    // Map formats using base MIME, not the whole string
    switch (baseMime) {
      case 'audio/wav':
      case 'audio/x-wav':
      case 'audio/wave':
      case 'audio/pcm':
        audioMime = 'audio/wav';
        filename = 'audio.wav';
        break;
        
      case 'audio/mp4':
      case 'audio/m4a':
        audioMime = 'audio/mp4';
        filename = 'audio.mp4';
        break;
        
      case 'audio/ogg':
      case 'audio/opus':
        audioMime = 'audio/ogg';
        filename = 'audio.ogg';
        break;
        
      default:
        // Keep WebM as WebM (default case)
        audioMime = 'audio/webm';
        filename = 'audio.webm';
    }
    
    // Validate audio headers based on format
    const header = buf.slice(0, 4).toString('hex');
    console.log(`üîç Audio header: ${header} (format: ${audioMime})`);
    
    // Additional validation for WebM containers
    if (audioMime === 'audio/webm') {
      if (header !== '1a45dfa3') {
        console.log(`‚ùå Invalid WebM header: ${header}, expected: 1a45dfa3`);
        console.log(`üö´ Rejecting WebM data - only complete containers should be processed`);
        return { text: "Invalid WebM container - only complete containers are supported", words: [] };
      }
      
      // Check for minimum WebM container size
      if (buf.length < 1000) {
        console.log(`‚ùå WebM container too small: ${buf.length} bytes`);
        return { text: "WebM container too small", words: [] };
      }
      
      console.log(`‚úÖ Valid WebM container detected (${buf.length} bytes)`);
    }
    
    // Add the audio buffer as a file
    formData.append('file', buf, {
      filename: filename,
      contentType: audioMime
    });
    formData.append('model_id', 'scribe_v1');
    formData.append('timestamps_granularity', 'word');
    
    // Make direct API call instead of using SDK
    const response = await fetch('https://api.elevenlabs.io/v1/speech-to-text', {
      method: 'POST',
      headers: {
        'xi-api-key': process.env.ELEVENLABS_KEY,
        ...formData.getHeaders()
      },
      body: formData
    });
    
    if (!response.ok) {
      const errorText = await response.text();
      console.error(`‚ùå ElevenLabs API error: ${response.status} ${response.statusText}`);
      console.error('Error response:', errorText);
      
      // Handle specific error cases
      if (response.status === 400) {
        try {
          const errorJson = JSON.parse(errorText);
          if (errorJson.detail?.message?.includes('corrupted')) {
            console.log("üîÑ Audio appears corrupted - this might be due to WebM container issues");
            console.log(`üìä Audio details: ${buf.length} bytes, format: ${audioMime}, header: ${buf.slice(0, 4).toString('hex')}`);
            return { text: "Audio quality issue - WebM container may be incomplete", words: [] };
          }
        } catch (e) {
          // If we can't parse the error, continue with generic error
        }
      }
      
      throw new Error(`API error: ${response.status} ${response.statusText}`);
    }
    
    const result = await response.json();
    console.log("‚úÖ ElevenLabs transcription successful");
    
    // Return both text and word-level data
    return {
      text: result.text || "No transcription available",
      words: result.words || []
    };
    
  } catch (err) {
    console.error("‚ùå Transcription error:", err);
    console.error("Error details:", err.message);
    
    // Return a more user-friendly error message
    if (err.message.includes('corrupted') || err.message.includes('invalid_content')) {
      return { text: "Audio quality issue - please try again", words: [] };
    }
    
    return { text: "Transcription temporarily unavailable", words: [] };
  }
}

async function summarise(text, customPrompt) {
  try {
    console.log(`üåê Calling Anthropic API for summarization`);
    const basePrompt = customPrompt || "Summarise the following classroom discussion in ‚â§6 clear bullet points:";
    
  const body = {
      model: "claude-sonnet-4-20250514",
      max_tokens: 800, // Reduced from 2000 - ultra-efficient prompt needs fewer tokens
      temperature: 0, // Set to 0 for maximum consistency
    messages: [
      {
          role: "user",
          content: `${basePrompt}\n\n${text}`
      }
    ]
  };

  const res = await fetch("https://api.anthropic.com/v1/messages", {
      method: "POST",
    headers: {
        "x-api-key": process.env.ANTHROPIC_KEY,
        "anthropic-version": "2023-06-01",
        "content-type": "application/json"
    },
    body: JSON.stringify(body)
  });
    
    if (!res.ok) {
      console.error(`‚ùå Anthropic API error: ${res.status} ${res.statusText}`);
      const errorText = await res.text();
      console.error("Error response:", errorText);
      return "Summarization failed";
    }

  const j = await res.json();
    console.log("‚úÖ Anthropic summarization successful");
  return j.content?.[0]?.text?.trim() ?? "(no summary)";
  } catch (err) {
    console.error("‚ùå Summarization error:", err);
    return "Summarization failed";
  }
}

async function processMindmapTranscript(text, mainTopic, existingNodes = []) {
  try {
    console.log(`üß† Processing transcript for mindmap...`);
    
    const existingNodesText = existingNodes.length > 0 ? 
      `\n\nExisting mindmap structure:\n${existingNodes.map(node => 
        `${node.level === 0 ? 'MAIN:' : node.level === 1 ? 'TOPIC:' : node.level === 2 ? 'SUBTOPIC:' : 'EXAMPLE:'} ${node.content}`
      ).join('\n')}` : '';
    
    const prompt = `You are analyzing classroom discussion to build a mindmap. The main topic is: "${mainTopic}"

Analyze this new transcript segment and determine:
1. Is this irrelevant chatter that should be ignored? 
2. If relevant, is it a new main point, subpoint, or example?
3. How should it fit into the existing mindmap structure?

${existingNodesText}

New transcript: "${text}"

Respond with JSON in this exact format:
{
  "action": "ignore|add_node",
  "reason": "brief explanation of your decision",
  "node": {
    "content": "the content to add (if action is add_node)",
    "level": 1,
    "parent_id": "id of parent node or null for main topics"
  }
}

Levels: 1=main topic, 2=subtopic, 3=sub-subtopic/example`;

    const body = {
      model: "claude-sonnet-4-20250514",
      max_tokens: 300,
      temperature: 0.3,
      messages: [
        {
          role: "user",
          content: prompt
        }
      ]
    };

    const res = await fetch("https://api.anthropic.com/v1/messages", {
      method: "POST",
      headers: {
        "x-api-key": process.env.ANTHROPIC_KEY,
        "anthropic-version": "2023-06-01",
        "content-type": "application/json"
      },
      body: JSON.stringify(body)
    });
    
    if (!res.ok) {
      console.error(`‚ùå Mindmap processing API error: ${res.status} ${res.statusText}`);
      return { action: "ignore", reason: "API error", node: null };
    }

    const response = await res.json();
    const result = JSON.parse(response.content?.[0]?.text?.trim() ?? '{"action": "ignore", "reason": "parsing error", "node": null}');
    
    console.log("‚úÖ Mindmap processing successful");
    return result;
  } catch (err) {
    console.error("‚ùå Mindmap processing error:", err);
    return { action: "ignore", reason: "Processing error", node: null };
  }
}

async function processCheckboxTranscript(text, criteria, scenario = "", strictness = 2, existingProgress = []) {
  try {
    console.log(`‚òëÔ∏è Processing transcript for 3-state checkbox evaluation (strictness: ${strictness})...`);
    
    // Check if API key is available
    const apiKey = process.env.ANTHROPIC_API_KEY || process.env.ANTHROPIC_KEY;
    if (!apiKey) {
      console.log(`üß™ ANTHROPIC API KEY not set - returning mock test data for demonstration`);
      console.log(`üîç Checked for: ANTHROPIC_API_KEY and ANTHROPIC_KEY environment variables`);
      
      // Return mock matches for testing when API key is not available
      const mockMatches = [];
      
      // Check for some obvious matches in the text for demonstration
      if (text.toLowerCase().includes('back titration') && text.toLowerCase().includes('not soluble')) {
        mockMatches.push({
          criteria_index: 0,
          quote: "back titration is used because CaCO3 is not soluble",
          status: "green"
        });
      }
      
      // Include existing GREEN criteria in the response
      existingProgress.forEach((progress, index) => {
        if (progress && progress.status === 'green') {
          mockMatches.push({
            criteria_index: index,
            quote: progress.quote,
            status: "green"
          });
        }
      });
      
      return {
        matches: mockMatches
      };
    }
    
    console.log(`‚úÖ Using Anthropic API for ${strictness === 1 ? 'LENIENT' : strictness === 2 ? 'MODERATE' : 'STRICT'} transcript analysis`);
    
    // Filter out already GREEN criteria from evaluation
    const criteriaToEvaluate = [];
    const greenCriteria = [];
    
    criteria.forEach((c, i) => {
      const progress = existingProgress[i];
      if (progress && progress.status === 'green') {
        // This criterion is already GREEN - don't re-evaluate
        greenCriteria.push({
          criteria_index: i,
          quote: progress.quote,
          status: "green"
        });
        console.log(`üìã Skipping evaluation for criteria ${i} - already GREEN with quote: "${progress.quote}"`);
      } else {
        // This criterion needs evaluation
        criteriaToEvaluate.push({ ...c, originalIndex: i });
      }
    });
    
    console.log(`üìã Evaluating ${criteriaToEvaluate.length} criteria (skipping ${greenCriteria.length} already GREEN)`);
    
    // If all criteria are already GREEN, just return them
    if (criteriaToEvaluate.length === 0) {
      console.log(`‚úÖ All criteria already GREEN - no evaluation needed`);
      return {
        matches: greenCriteria
      };
    }
    
    // Create detailed criteria text with rubrics for evaluation
    const criteriaText = criteriaToEvaluate.map((c, i) => {
      return `${c.originalIndex}. ${c.description}\n   RUBRIC: ${c.rubric}`;
    }).join('\n\n');
    
    const scenarioContext = scenario ? `\nDiscussion Context/Scenario: ${scenario}\n` : '';
    
    // Adjust evaluation framework based on strictness level
    let evaluationFramework = '';
    
    if (strictness === 1) { // Lenient
      evaluationFramework = `
üü¢ GREEN STATUS - Award when:
‚Ä¢ Student demonstrates general understanding of the concept
‚Ä¢ The main idea is correct, even if some details are missing
‚Ä¢ Accept partial explanations that show conceptual grasp
‚Ä¢ Be generous with interpretations - if they're on the right track, it's GREEN
‚Ä¢ Accept different ways of expressing the same concept

üî¥ RED STATUS - Award when:
‚Ä¢ Student mentions the topic but shows fundamental misunderstanding
‚Ä¢ Major conceptual errors are present
‚Ä¢ The core idea is wrong, even if they tried

‚ö™ GREY STATUS - Award when:
‚Ä¢ The topic is NOT discussed at all
‚Ä¢ No evidence exists that the student engaged with this concept
‚Ä¢ Set quote to null for grey items`;
    } else if (strictness === 3) { // Strict
      evaluationFramework = `
üü¢ GREEN STATUS - Award ONLY when:
‚Ä¢ Student demonstrates COMPLETE and PRECISE understanding
‚Ä¢ ALL rubric requirements must be explicitly addressed
‚Ä¢ The explanation must be thorough and accurate
‚Ä¢ Every detail specified in the rubric must be present
‚Ä¢ No partial credit - it's either fully correct or not

üî¥ RED STATUS - Award when:
‚Ä¢ Student attempts the topic but ANY rubric requirement is missing
‚Ä¢ Even minor inaccuracies or omissions result in RED
‚Ä¢ Partial understanding is still RED if not complete

‚ö™ GREY STATUS - Award when:
‚Ä¢ The topic is NOT discussed at all
‚Ä¢ No evidence exists that the student engaged with this concept
‚Ä¢ Set quote to null for grey items`;
    } else { // Moderate (default)
      evaluationFramework = `
üü¢ GREEN STATUS - Award ONLY when:
‚Ä¢ Student demonstrates understanding of BOTH the label concept AND the rubric requirements
‚Ä¢ The RUBRIC requirements (in parentheses) MUST be addressed (even if expressed differently)
‚Ä¢ Accept different ways of expressing the same concept:
  - "0.1 cm¬≥", "0.10 cm cube", "0.1 cubic centimeters" all mean the same thing
  - "2 consistent results" = "two consistent results" = "after 2 consistent titrations"
  - Numbers can be expressed as digits or words
‚Ä¢ Their explanation must align with BOTH the label AND the specific rubric details
‚Ä¢ Accept phonetic variations (e.g., "metal orange" = "methyl orange") but require conceptual accuracy

üî¥ RED STATUS - Award when:
‚Ä¢ Student mentions the topic/label but FAILS to address the rubric requirements
‚Ä¢ Student attempts the concept but misses key rubric details
‚Ä¢ Student shows partial understanding but lacks the specific rubric content
‚Ä¢ They demonstrate engagement but don't meet the rubric criteria
‚Ä¢ IMPORTANT: If they mention WRONG information (e.g., "10 consistent results" instead of "2"), mark as RED

‚ö™ GREY STATUS - Award when:
‚Ä¢ The topic is NOT discussed at all
‚Ä¢ No evidence exists that the student engaged with this concept
‚Ä¢ Set quote to null for grey items`;
    }
    
    const prompt = `You are an expert educational evaluator analyzing student discussion transcripts against specific learning objectives. Your task is to provide precise, consistent evaluations using a 3-state system.

${strictness === 1 ? 'EVALUATION MODE: LENIENT - Be generous and focus on conceptual understanding' : 
  strictness === 3 ? 'EVALUATION MODE: STRICT - Require complete and precise answers with all details' : 
  'EVALUATION MODE: MODERATE - Balance conceptual understanding with important details'}

INDEXED OBJECTIVES (use the IDX numbers exactly as shown):
${criteriaToEvaluate.map(c => `IDX ${c.originalIndex}: ${c.description}\nRUBRIC: ${c.rubric}`).join('\n\n')}

IMPORTANT: When you output matches, the "criteria_index" value MUST be one of the IDX numbers shown above. Do not invent or shift indices. If multiple objectives seem possible, choose the single best match by rubric alignment.

STUDENT DISCUSSION TRANSCRIPT:
"${text}"

${scenarioContext}

EVALUATION FRAMEWORK:
${evaluationFramework}

CRITICAL EVALUATION RULES:

1. ${strictness === 1 ? 'FLEXIBLE MATCHING' : strictness === 3 ? 'EXACT MATCHING' : 'INTELLIGENT MATCHING'}:
   ${strictness === 1 ? 
   `- Accept any reasonable interpretation of the concept
   - Partial understanding is often sufficient for GREEN
   - Focus on whether they grasp the main idea` : 
   strictness === 3 ? 
   `- Require precise and complete answers
   - All rubric details must be explicitly stated
   - No assumptions or generous interpretations` :
   `- The rubric content is important but can be expressed differently
   - Accept equivalent expressions and terminology
   - Look for the MEANING, not exact wording`}

2. TRANSCRIPTION ERROR TOLERANCE AND SYNONYMS:
   - Accept phonetically similar terms (metal orange ‚âà methyl orange)
   - Units/expressions equivalence: cm¬≥ = cm3 = cm cubed = cubic centimeters
   - Chemical/name equivalence: HCl = hydrochloric acid; CaCO3 = calcium carbonate; insoluble ‚âà not soluble
   - Common ASR artifacts: "title volume" ‚âà "titre volume"; "titer" ‚âà "titre"
   - Accept digit/word variations (2 = two, 0.1 = 0.10)
   - Focus on conceptual understanding over exact pronunciation

3. SPECIFICITY:
   - Map each quote to ONE best objective (do not duplicate a quote across objectives)
   - Prefer the objective whose rubric terms most closely appear in the quote

4. QUOTE SELECTION:
   - For GREEN/RED, include a short exact quote that demonstrates why
   - For GREY, set quote to null

RESPONSE FORMAT (JSON ONLY):
{
  "matches": [ { "criteria_index": <IDX>, "quote": <string|null>, "status": "green|red|grey", "why": <string|null> } ]
}

QUALITY CHECK:
- Use only the provided IDX values
- No explanations outside JSON
- Prefer the objective with the strongest rubric term overlap with the quote

Begin evaluation now:`;

    const body = {
      model: "claude-sonnet-4-20250514", // Using Claude Sonnet 4 as requested
      max_tokens: 2000, // Increased for comprehensive prompt and detailed analysis
      temperature: 0, // Set to 0 for maximum consistency
      messages: [
        {
          role: "user",
          content: prompt
        }
      ]
    };

    const res = await fetch("https://api.anthropic.com/v1/messages", {
      method: "POST",
      headers: {
        "x-api-key": apiKey,
        "anthropic-version": "2023-06-01",
        "content-type": "application/json"
      },
      body: JSON.stringify(body)
    });
    
    if (!res.ok) {
      console.error(`‚ùå Checkbox processing API error: ${res.status} ${res.statusText}`);
      return { matches: [] };
    }

    const response = await res.json();
    const responseText = response.content?.[0]?.text?.trim();
    
    console.log(`üîç Anthropic response text: "${responseText?.substring(0, 300)}..."`);
    
    let result;
    try {
      // Try to parse the JSON response
      result = JSON.parse(responseText ?? '{"matches": []}');
    } catch (parseError) {
      console.error("‚ùå JSON parse error:", parseError.message);
      console.error("üîç Raw response text:", responseText);
      
      // Try to extract JSON from the response if it's wrapped in other text
      const jsonMatch = responseText?.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        try {
          result = JSON.parse(jsonMatch[0]);
          console.log("‚úÖ Recovered JSON from wrapped response");
        } catch (secondError) {
          console.error("‚ùå Could not parse extracted JSON either");
          result = { matches: [] };
        }
      } else {
        result = { matches: [] };
      }
    }
    
    // Validate the result structure
    if (!result || typeof result !== 'object') {
      console.warn("‚ö†Ô∏è Invalid response structure (not an object), creating default structure");
      result = { matches: [] };
    }
    
    if (!result.matches || !Array.isArray(result.matches)) {
      console.warn("‚ö†Ô∏è Missing or invalid matches array, creating empty array");
      result.matches = [];
    }
    
    // Validate each match object with 'why' rationale
    result.matches = result.matches.filter(match => {
      // Coerce criteria_index if Anthropic returns string like 'IDX 6' or '6'
      if (typeof match?.criteria_index === 'string') {
        const m = match.criteria_index.match(/(\d+)/);
        if (m) {
          match.criteria_index = Number(m[1]);
        }
      }
      if (typeof match !== 'object' || 
          typeof match.criteria_index !== 'number' ||
          typeof match.status !== 'string') {
        console.warn("‚ö†Ô∏è Invalid match object structure:", match);
        return false;
      }
      
      // Validate quote based on status: grey should have null, others should have string
      if (match.status === 'grey') {
        if (match.quote !== null && match.quote !== undefined) {
          console.warn(`‚ö†Ô∏è Grey status should have null quote, got: ${match.quote}`);
          match.quote = null; // Fix it rather than reject
        }
        if (match.why === undefined) match.why = null;
      } else {
        if (typeof match.quote !== 'string' || match.quote.trim() === '') {
          console.warn(`‚ö†Ô∏è ${match.status} status must have non-empty string quote, got:`, match.quote);
          return false;
        }
        if (typeof match.why !== 'string' || match.why.trim() === '') {
          // Fill a concise default if missing
          match.why = 'Quote aligns with rubric terms for this objective.';
        }
        if (match.why.length > 180) {
          match.why = match.why.slice(0, 180);
        }
      }
      
      // Validate criteria_index is within valid range
      if (match.criteria_index < 0 || match.criteria_index >= criteria.length) {
        console.warn(`‚ö†Ô∏è Invalid criteria_index ${match.criteria_index}. Valid range: 0-${criteria.length - 1}`);
        return false;
      }
      
      // Validate status is one of the allowed values
      if (!['green', 'red', 'grey'].includes(match.status)) {
        console.warn(`‚ö†Ô∏è Invalid status "${match.status}". Must be green, red, or grey`);
        return false;
      }
      
      return true;
    });
    
    // Detect and warn about duplicate quotes (same quote assigned to multiple criteria)
    const quoteMap = new Map();
    result.matches.forEach(match => {
      if (match.quote && match.status !== 'grey') {
        const trimmedQuote = match.quote.trim();
        if (quoteMap.has(trimmedQuote)) {
          console.warn(`üö® DUPLICATE QUOTE DETECTED: Quote "${trimmedQuote.substring(0, 50)}..." assigned to multiple criteria: ${quoteMap.get(trimmedQuote)} and ${match.criteria_index}`);
        } else {
          quoteMap.set(trimmedQuote, match.criteria_index);
        }
      }
    });
    
    // If we have duplicate quotes, mark all but the first as grey
    if (quoteMap.size < result.matches.filter(m => m.status !== 'grey').length) {
      console.warn(`üîß Fixing duplicate quotes by marking duplicates as grey`);
      const seenQuotes = new Set();
      result.matches.forEach(match => {
        if (match.quote && match.status !== 'grey') {
          const trimmedQuote = match.quote.trim();
          if (seenQuotes.has(trimmedQuote)) {
            console.warn(`üîß Marking criteria ${match.criteria_index} as grey due to duplicate quote`);
            match.status = 'grey';
            match.quote = null;
          } else {
            seenQuotes.add(trimmedQuote);
          }
        }
      });
    }
    
    // Dynamic rerouting based on rubric-driven token overlap (no hardcoded categories)
    const norm = (s) => (s || '').toLowerCase()
      .replace(/title volume/g, 'titre volume')
      .replace(/titer/g, 'titre')
      .replace(/cm\^?3|cubic\s*cent(imetre|imeter)s?|cm\s*cubed/g, 'cm3')
      .replace(/hcl/g, 'hydrochloric acid');

    const STOPWORDS = new Set(['the','and','for','that','this','with','will','must','have','has','are','was','were','can','could','should','would','to','of','in','on','at','by','from','or','as','be','is','a','an','it','we','you','they','between']);
    const tokenize = (s) => norm(s)
      .replace(/[^a-z0-9\.\s]/g,' ')
      .split(/\s+/)
      .filter(w => w && !STOPWORDS.has(w) && w.length > 2);

    const criterionTokens = criteria.map(c => new Set(tokenize(`${c.description} ${c.rubric}`)));

    const scoreOverlap = (quote, idx) => {
      if (!quote) return 0;
      const qt = tokenize(quote);
      const dict = criterionTokens[idx];
      let score = 0;
      for (const t of qt) if (dict.has(t)) score++;
      return score;
    };

    result.matches = result.matches.map(m => {
      if (!m.quote || m.status === 'grey') return m;
      const current = m.criteria_index;
      let bestIdx = current;
      let bestScore = scoreOverlap(m.quote, current);
      for (let i = 0; i < criteria.length; i++) {
        const sc = scoreOverlap(m.quote, i);
        if (sc > bestScore) { bestScore = sc; bestIdx = i; }
      }
      // Reroute only when there is a clear improvement and current match is weak
      if (bestIdx !== current && bestScore >= Math.max(2, bestScore - 0) && bestScore >= (scoreOverlap(m.quote, current) + 2)) {
        console.log(`üîÄ Re-routing match from idx=${current} to idx=${bestIdx} based on token overlap (old=${scoreOverlap(m.quote, current)}, new=${bestScore})`);
        return { ...m, criteria_index: bestIdx };
      }
      return m;
    });

    // Cleanup duplicate quotes after rerouting
    (function cleanupDuplicates() {
      const seen = new Map();
      result.matches.forEach(m => {
        if (!m.quote || m.status === 'grey') return;
        const key = m.quote.trim();
        if (!seen.has(key)) { seen.set(key, m.criteria_index); return; }
        if (seen.get(key) !== m.criteria_index) {
          console.warn(`üîß Removing duplicate quote after reroute from idx=${m.criteria_index}`);
          m.status = 'grey';
          m.quote = null;
        }
      });
    })();
    
    console.log(`‚úÖ 3-state checkbox processing successful: ${result.matches.length} valid matches found`);
    console.log(`üìä Status breakdown:`, result.matches.reduce((acc, match) => {
      acc[match.status] = (acc[match.status] || 0) + 1;
      return acc;
    }, {}));
    
    // Build complete matches array for ALL criteria
    const allMatches = [];
    
    // Process each criterion to ensure we have a match for every one
    criteria.forEach((criterion, index) => {
      // Check if this criterion was in greenCriteria (preserved)
      const greenMatch = greenCriteria.find(m => m.criteria_index === index);
      if (greenMatch) {
        allMatches.push(greenMatch);
        return;
      }
      
      // Check if this criterion was in the AI evaluation results
      const aiMatch = result.matches.find(m => m.criteria_index === index);
      if (aiMatch) {
        allMatches.push(aiMatch);
        return;
      }
      
      // If not found in either, preserve the existing status or default to grey
      const existingProg = existingProgress[index];
      if (existingProg) {
        // Preserve existing RED or GREY status that wasn't re-evaluated
        allMatches.push({
          criteria_index: index,
          quote: existingProg.quote || null,
          status: existingProg.status || 'grey'
        });
      } else {
        // No existing progress, default to grey
        allMatches.push({
          criteria_index: index,
          quote: null,
          status: 'grey'
        });
      }
    });
    
    // Sort by criteria_index for consistent ordering
    allMatches.sort((a, b) => a.criteria_index - b.criteria_index);
    
    console.log(`üìä Complete results: ${allMatches.length} total matches for ${criteria.length} criteria`);
    console.log(`üìä Final status breakdown:`, allMatches.reduce((acc, match) => {
      acc[match.status] = (acc[match.status] || 0) + 1;
      return acc;
    }, {}));
    
    return { matches: allMatches };
  } catch (err) {
    console.error("‚ùå Checkbox processing error:", err);
    return { matches: [] };
  }
}

// Clean up on server shutdown
process.on('SIGINT', async () => {
  console.log('üõë Server shutting down...');
  
  // Stop all auto-summary timers
  for (const [sessionCode, timer] of activeSummaryTimers) {
    clearInterval(timer);
    console.log(`‚è∞ Stopped timer for session ${sessionCode}`);
  }
  
  // Mark all sessions as inactive in database
  await db.collection("sessions").updateMany({}, { $set: { active: false } });
  console.log('üíæ Marked all sessions as inactive');
  
  process.exit(0);
});

/* New 30-second chunk transcription endpoint */
app.post("/api/transcribe-chunk", upload.single('file'), async (req, res) => {
  try {
    console.log("üì¶ Received chunk for transcription");
    
    if (!req.file) {
      return res.status(400).json({ error: "No audio file provided", success: false });
    }
    
    const audioBuffer = req.file.buffer;
    const mimeType = req.file.mimetype;
    const { sessionCode, groupNumber } = req.body;
    
    if (!sessionCode || !groupNumber) {
      return res.status(400).json({ error: "Session code and group number are required", success: false });
    }
    
    console.log(`üìÅ Processing chunk: ${audioBuffer.length} bytes, mimetype: ${mimeType}, session: ${sessionCode}, group: ${groupNumber}`);
    
    // Enhanced chunk validation
    if (audioBuffer.length < 100) {
      console.log("‚ö†Ô∏è Chunk too small, skipping");
      return res.json({ 
        success: false, 
        message: "Chunk too small (< 100 bytes)",
        transcription: { text: "", words: [] }
      });
    }
    
    if (audioBuffer.length > 10 * 1024 * 1024) { // 10MB limit
      console.log("‚ö†Ô∏è Chunk too large, skipping");
      return res.status(400).json({ error: "Chunk too large (>10MB)", success: false });
    }
    
    // Validate audio format
    const header = audioBuffer.slice(0, 4).toString('hex');
    const validHeaders = {
      '1a45dfa3': 'WebM',
      '52494646': 'WAV/RIFF',
      '00000020': 'MP4',
      '4f676753': 'OGG'
    };
    
    if (!validHeaders[header]) {
      console.log(`‚ö†Ô∏è Unknown audio format, header: ${header}`);
      // Don't reject - ElevenLabs might still be able to process it
    } else {
      console.log(`‚úÖ Detected ${validHeaders[header]} format`);
    }
    
    // Validate WebM containers more strictly
    if (mimeType.includes('webm') && header !== '1a45dfa3') {
      console.log(`‚ùå Invalid WebM container, header: ${header}`);
      return res.status(400).json({ 
        error: "Invalid WebM container - corrupted audio data", 
        success: false,
        details: `Expected WebM header 1a45dfa3, got ${header}`
      });
    }
    
    // Direct forward to ElevenLabs using form-data with retry logic
    const FormData = (await import('form-data')).default;
    const formData = new FormData();
    
    formData.append('model_id', 'scribe_v1');
    formData.append('file', audioBuffer, {
      filename: req.file.originalname || `chunk_${Date.now()}.webm`,
      contentType: mimeType
    });
    
    console.log("üåê Forwarding to ElevenLabs Speech-to-Text API...");
    
    const startTime = Date.now();
    let response;
    let retryCount = 0;
    const maxRetries = 3;
    
    // Retry logic for ElevenLabs API
    while (retryCount < maxRetries) {
      try {
        response = await fetch('https://api.elevenlabs.io/v1/speech-to-text', {
          method: 'POST',
          headers: {
            'xi-api-key': process.env.ELEVENLABS_KEY,
            ...formData.getHeaders()
          },
          body: formData,
          timeout: 30000 // 30 second timeout
        });
        
        if (response.ok) {
          break; // Success, exit retry loop
        } else if (response.status === 429) {
          // Rate limit - wait and retry
          console.log(`‚è≥ Rate limited, retrying in ${Math.pow(2, retryCount)} seconds...`);
          await new Promise(resolve => setTimeout(resolve, Math.pow(2, retryCount) * 1000));
          retryCount++;
        } else if (response.status >= 500) {
          // Server error - retry
          console.log(`üîÑ Server error ${response.status}, retrying...`);
          retryCount++;
          await new Promise(resolve => setTimeout(resolve, 1000));
        } else {
          // Client error - don't retry
          break;
        }
      } catch (fetchError) {
        console.error(`‚ùå Network error (attempt ${retryCount + 1}):`, fetchError);
        retryCount++;
        if (retryCount < maxRetries) {
          await new Promise(resolve => setTimeout(resolve, Math.pow(2, retryCount) * 1000));
        }
      }
    }
    
    const processingTime = Date.now() - startTime;
    
    if (!response || !response.ok) {
      let errorText = 'Unknown error';
      try {
        errorText = await response.text();
      } catch (e) {
        // Ignore text parsing errors
      }
      
      console.error(`‚ùå ElevenLabs API error after ${retryCount} retries: ${response?.status} ${response?.statusText}`);
      console.error('Error response:', errorText);
      
      // Return more specific error messages
      let errorMessage = "Transcription service temporarily unavailable";
      if (response?.status === 400) {
        errorMessage = "Audio format not supported or corrupted";
      } else if (response?.status === 401) {
        errorMessage = "Transcription service authentication failed";
      } else if (response?.status === 429) {
        errorMessage = "Transcription service rate limit exceeded";
      } else if (response?.status >= 500) {
        errorMessage = "Transcription service server error";
      }
      
      return res.status(response?.status || 500).json({ 
        error: errorMessage,
        details: errorText,
        success: false,
        retryCount: retryCount
      });
    }
    
    const result = await response.json();
    console.log(`‚úÖ ElevenLabs transcription successful (${processingTime}ms, ${retryCount} retries)`);
    
    // Use the raw transcription without cleaning
    let transcriptionText = result.text || "";
    
    // Skip empty transcriptions
    if (!transcriptionText.trim()) {
      console.log("‚ö†Ô∏è Empty transcription result, skipping database save");
      return res.json({
        success: true,
        message: "Empty transcription - no speech detected",
        transcription: {
          text: "",
          words: [],
          duration: 0,
          wordCount: 0
        },
        processingTime: `${processingTime}ms`,
        chunkSize: audioBuffer.length
      });
    }
    
    // Save to database and generate summary
    try {
      // Get session and group
      const session = await db.collection("sessions").findOne({ code: sessionCode });
      if (!session) {
        console.log(`‚ö†Ô∏è  Session ${sessionCode} not found in database - session may not have started recording yet`);
        return res.json({
          success: true,
          message: "Session not yet persisted - transcription processed but not saved",
          transcription: {
            text: transcriptionText,
            words: result.words || [],
            duration: result.words && result.words.length > 0 ? 
              result.words[result.words.length - 1].end : 
              Math.max(5, Math.min(60, transcriptionText.split(' ').length * 0.5)),
            wordCount: result.words ? result.words.length : 
              transcriptionText.split(' ').filter(w => w.trim().length > 0).length
          },
          processingTime: `${processingTime}ms`,
          chunkSize: audioBuffer.length
        });
      }
      
      // Define the timestamp for this processing
      const now = Date.now();
      
      const group = await db.collection("groups").findOne({ 
        session_id: session._id, 
        number: parseInt(groupNumber) 
      });
      if (!group) {
        console.log(`‚ö†Ô∏è  Group ${groupNumber} not found in database - creating new group`);
        
        // Create the group since it doesn't exist
        const newGroupId = uuid();
        await db.collection("groups").insertOne({
          _id: newGroupId,
          session_id: session._id,
          number: parseInt(groupNumber)
        });
        
        console.log(`üìù Created new group: Session ${sessionCode}, Group ${groupNumber}, ID: ${newGroupId}`);
        
        // Continue with the newly created group
        const newGroup = { _id: newGroupId, session_id: session._id, number: parseInt(groupNumber) };
        
        // Save transcription and continue processing with the new group
        await processTranscriptionForGroup(session, newGroup, transcriptionText, result, now, sessionCode, groupNumber);
      } else {
        // Process with existing group
        await processTranscriptionForGroup(session, group, transcriptionText, result, now, sessionCode, groupNumber);
      }
      
      console.log(`‚úÖ Transcription and summary saved for session ${sessionCode}, group ${groupNumber}`);
      
    } catch (dbError) {
      console.error("‚ùå Database error:", dbError);
      // Still return success for transcription even if DB fails
      return res.json({
        success: true,
        message: "Transcription successful but database save failed",
        transcription: {
          text: transcriptionText,
          words: result.words || [],
          duration: result.words && result.words.length > 0 ? 
            result.words[result.words.length - 1].end : 
            Math.max(5, Math.min(60, transcriptionText.split(' ').length * 0.5)),
          wordCount: result.words ? result.words.length : 
            transcriptionText.split(' ').filter(w => w.trim().length > 0).length
        },
        processingTime: `${processingTime}ms`,
        chunkSize: audioBuffer.length,
        dbError: dbError.message
      });
    }
    
    const finalResult = {
      success: true,
      transcription: {
        text: transcriptionText,
        words: result.words || [],
        duration: result.words && result.words.length > 0 ? 
          result.words[result.words.length - 1].end : 
          Math.max(5, Math.min(60, transcriptionText.split(' ').length * 0.5)),
        wordCount: result.words ? result.words.length : 
          transcriptionText.split(' ').filter(w => w.trim().length > 0).length
      },
      processingTime: `${processingTime}ms`,
      chunkSize: audioBuffer.length,
      retryCount: retryCount
    };
    
    console.log("üìù Chunk transcription result:", {
      text: transcriptionText.substring(0, 100) + (transcriptionText.length > 100 ? "..." : ""),
      wordCount: finalResult.transcription.wordCount,
      duration: finalResult.transcription.duration,
      retries: retryCount
    });
    
    res.json(finalResult);
    
  } catch (err) {
    console.error("‚ùå Chunk transcription error:", err);
    res.status(500).json({ 
      error: "Internal server error during transcription", 
      details: err.message,
      success: false,
      stack: process.env.NODE_ENV === 'development' ? err.stack : undefined
    });
  }
});

// Helper function to process transcription for a group
async function processTranscriptionForGroup(session, group, transcriptionText, result, now, sessionCode, groupNumber) {
  try {
    // Ensure 'now' is defined if not passed
    if (!now) {
      now = Date.now();
    }
    
    // Filter out background noise, music, and non-educational content
    const lowerText = transcriptionText.toLowerCase().trim();
    const noisePatterns = [
      /^\(.*music.*\)$/,
      /^\(.*background.*\)$/,
      /^\(.*noise.*\)$/,
      /^\(.*chattering.*\)$/,
      /^\(.*wind.*blowing.*\)$/,
      /^\(.*keyboard.*\)$/,
      /^\(.*clicking.*\)$/,
      /^\(.*typing.*\)$/,
      /^\(.*computer.*\)$/,
      /^testing,?\s*testing\.?$/,
      /^what the hell/,
      /^okay\.?\s*\(pauses?\)\s*okay/,
      /^cualquiera que sea/,
      /^Î∞∞Í≤Ω ÏÜåÏùå/,
      /^Í∏∞Í≥ÑÏùå ÏÜåÎ¶¨/,
      /^bis zum n√§chsten mal/,
      /^bis dann/,
      /^haus zu hause/,
      /^kszta≈Çcenie/,
      /^klikanie/,
      /^ger√§usch vom tippen/,
      /^ronco de moto/,
      /^\(.*sounds?\)$/,
      /^\(.*audio.*\)$/,
      /^\(.*mechanical.*\)$/
    ];
    
    const isNoise = noisePatterns.some(pattern => pattern.test(lowerText)) ||
                   lowerText.length < 15 || // Increased from 10 to 15 - too short to be meaningful
                   /^[\(\)\s\.,!?]*$/.test(lowerText) || // Only punctuation/parentheses
                   /^\([^)]*\)\s*\([^)]*\)$/.test(lowerText); // Only parenthetical descriptions
    
    if (isNoise) {
      console.log(`üîá Noise/background transcript (still logging to UI): "${transcriptionText.substring(0, 50)}..."`);
      // Log minimal transcript entry for timeline
      const transcriptId = uuid();
      await db.collection("transcripts").insertOne({
        _id: transcriptId,
        group_id: group._id,
        text: transcriptionText,
        word_count: transcriptionText.split(' ').filter(w => w.trim().length > 0).length,
        duration_seconds: 0,
        created_at: now,
        segment_number: Math.floor(now / (session.interval_ms || 30000)),
        is_noise: true
      });
      // Emit to teacher so transcript list shows every update
      io.to(sessionCode).emit("admin_update", {
        group: groupNumber,
        latestTranscript: transcriptionText,
        checkboxUpdates: [],
        isActive: true
      });
      return; // Do not run AI processing for noise
    }
    
    // Save the transcription segment
    const transcriptId = uuid();
    
    const wordCount = result.words && result.words.length > 0 ? 
      result.words.length : 
      transcriptionText.split(' ').filter(w => w.trim().length > 0).length;
    
    const duration = result.words && result.words.length > 0 ? 
      result.words[result.words.length - 1].end : 
      Math.max(5, Math.min(60, transcriptionText.split(' ').length * 0.5));
    
    await db.collection("transcripts").insertOne({
      _id: transcriptId,
      group_id: group._id,
      text: transcriptionText,
      word_count: wordCount,
      duration_seconds: duration,
      created_at: now,
      segment_number: Math.floor(now / (session.interval_ms || 30000))
    });
    
    // Check if this is a checkbox mode session
    if (session.mode === "checkbox") {
      console.log(`‚òëÔ∏è Processing checkbox mode transcript for session ${sessionCode}, group ${groupNumber}`);
      
      // Get checkbox session data and criteria
      const checkboxSession = await db.collection("checkbox_sessions").findOne({ session_id: session._id });
      const criteria = await db.collection("checkbox_criteria")
        .find({ session_id: session._id })
        .sort({ order_index: 1, created_at: 1 })
        .toArray();
      
      if (criteria.length > 0) {
        // Get the entire conversation so far for this group (full context)
        const allTranscriptsForGroup = await db.collection("transcripts")
          .find({ 
            group_id: group._id
          })
          .sort({ created_at: 1 }) // Chronological order
          .toArray();
        
        // Join everything up to the current point
        const concatenatedText = allTranscriptsForGroup.map(t => t.text).join(' ').trim();
        
        console.log(`üìã Using FULL context for checkbox analysis: ${allTranscriptsForGroup.length} segments`);
        
        // Get existing progress for this group to avoid re-evaluating GREEN criteria
        const existingProgressRecords = await db.collection("checkbox_progress")
          .find({ 
            session_id: session._id,
            group_number: groupNumber 
          })
          .toArray();
        
        // Build existing progress array indexed by criteria position
        const existingProgress = [];
        criteria.forEach((c, idx) => {
          const progress = existingProgressRecords.find(p => p.criteria_id === c._id);
          if (progress) {
            existingProgress[idx] = {
              status: progress.status,
              quote: progress.quote,
              completed: progress.completed
            };
          } else {
            existingProgress[idx] = null;
          }
        });
        
        console.log(`üìã Found ${existingProgressRecords.length} existing progress records`);
        const greenCount = existingProgress.filter(p => p && p.status === 'green').length;
        if (greenCount > 0) {
          console.log(`üìã Preserving ${greenCount} GREEN criteria from previous evaluations`);
        }
        
        // Process through checkbox analysis with concatenated text
        const scenario = checkboxSession?.scenario || "";
        const strictness = session.strictness || 2; // Get strictness from session, default to moderate
        const checkboxResult = await processCheckboxTranscript(concatenatedText.trim(), criteria, scenario, strictness, existingProgress);
        
        // Log the checkbox processing result
        await db.collection("session_logs").insertOne({
          _id: uuid(),
          session_id: session._id,
          type: "checkbox_analysis",
          content: concatenatedText.trim(),
          ai_response: checkboxResult,
          created_at: now
        });
        
        // Update progress for matched criteria
        const progressUpdates = [];
        for (const match of checkboxResult.matches) {
          const criterion = criteria[match.criteria_index];
          if (criterion) {
            // Check existing progress to implement proper locking rules
            const existingProgress = await db.collection("checkbox_progress").findOne({
              session_id: session._id,
              criteria_id: criterion._id
            });
            
            // Implement locking rules:
            // 1. GREEN stays GREEN forever (locked)
            // 2. GREY has no quotes and can become RED or GREEN
            // 3. RED can become GREEN but not GREY
            let shouldUpdate = false;
            let newStatus = match.status;
            let newQuote = match.status === 'grey' ? null : match.quote; // Grey has no quotes
            
            if (!existingProgress) {
              // No existing progress - always update
              shouldUpdate = true;
            } else if (existingProgress.status === 'green') {
              // GREEN is locked - never update
              console.log(`üìã Criteria ${match.criteria_index} already GREEN (locked) with quote: "${existingProgress.quote}" - skipping update`);
              shouldUpdate = false;
            } else if (existingProgress.status === 'grey') {
              // GREY can become RED or GREEN
              if (match.status === 'red' || match.status === 'green') {
                shouldUpdate = true;
                console.log(`üìã Criteria ${match.criteria_index} upgrading from GREY to ${match.status.toUpperCase()}`);
              }
            } else if (existingProgress.status === 'red') {
              // RED can only become GREEN
              if (match.status === 'green') {
                shouldUpdate = true;
                console.log(`üìã Criteria ${match.criteria_index} upgrading from RED to GREEN`);
              } else {
                console.log(`üìã Criteria ${match.criteria_index} staying RED - cannot downgrade to ${match.status.toUpperCase()}`);
                shouldUpdate = false;
              }
            }
            
            if (shouldUpdate) {
              await db.collection("checkbox_progress").findOneAndUpdate(
                { 
                  session_id: session._id,
                  criteria_id: criterion._id,
                  group_number: groupNumber  // Add group_number to the query
                },
                {
                  $set: {
                    completed: newStatus === 'green', // Only mark as completed if green
                    quote: newQuote, // No quote for grey status
                    status: newStatus,
                    completed_at: now,
                    group_number: groupNumber  // Ensure group_number is set
                  }
                },
                { upsert: true }
              );
              
              // Emit using both stable DB criteria_id and display index to avoid off-by-one errors
              progressUpdates.push({
                criteriaId: match.criteria_index,
                criteriaDbId: criterion._id,
                description: criterion.description,
                completed: match.status === 'green',
                quote: match.quote,
                status: match.status
              });
              
              console.log(`üìã Checkbox update for criteria idx=${match.criteria_index} (_id=${criterion._id}): "${match.quote}" - STATUS: ${match.status}`);
            } else {
              console.log(`üìã Criteria ${match.criteria_index} already completed with quote: "${existingProgress.quote}" - skipping update`);
            }
          }
        }
        
        console.log(`üì§ Sending ${progressUpdates.length} checkbox updates to admin for group ${groupNumber}`);
        
        // Send checkbox updates to admin
        io.to(sessionCode).emit("admin_update", {
          group: groupNumber,
          latestTranscript: transcriptionText,
          checkboxUpdates: progressUpdates,
          isActive: true
        });
        
        
        // NEW: Also emit full checklist state to both teachers and students
        // Get the current release state from database
        const checkboxSessionData = await db.collection("checkbox_sessions").findOne({ session_id: session._id });
        const isReleased = checkboxSessionData?.released_groups?.[groupNumber] || false;
        
        // Get all current progress for this group
        const allProgress = await db.collection("checkbox_progress").find({
          session_id: session._id,
          group_number: groupNumber
        }).toArray();
        
        // Build complete checklist state
        const checklistData = {
          groupNumber: groupNumber,
          criteria: criteria.map((c, idx) => {
            const progress = allProgress.find(p => p.criteria_id === c._id);
            return {
              id: idx, // stable index based on sorted order_index
              dbId: c._id,
              description: c.description,
              rubric: c.rubric || '',
              status: progress?.status || 'grey',
              completed: progress?.completed || false,
              quote: progress?.quote || null
            };
          }),
          scenario: checkboxSession?.scenario || "",
          timestamp: Date.now(),
          isReleased: isReleased,  // Controls student visibility
          sessionCode: sessionCode
        };
        
        console.log(`üì® Emitting checklist state to all (released: ${isReleased})`);
        
        // Emit to everyone in session
        io.to(sessionCode).emit('checklist_state', checklistData);
        io.to(`${sessionCode}-${groupNumber}`).emit('checklist_state', checklistData);
        // Cache latest state
        latestChecklistState.set(`${sessionCode}-${groupNumber}`, checklistData);
        
        // Send transcription to students in checkbox mode
        const roomName = `${sessionCode}-${groupNumber}`;
        io.to(roomName).emit("transcription_and_summary", {
          transcription: {
            text: transcriptionText, // Current chunk only
            cumulativeText: concatenatedText, // Full recent conversation
            words: result.words,
            duration: duration,
            wordCount: wordCount
          },
          summary: "Checkbox mode: Real-time discussion analysis", // Simple summary for checkbox mode
          isLatestSegment: true
        });
        
        console.log(`‚úÖ Checkbox analysis complete: ${checkboxResult.matches.length} criteria matched for group ${groupNumber}`);
      }
      
    } else {
      // Regular summary mode processing
      console.log(`üìù Processing summary mode transcript for session ${sessionCode}, group ${groupNumber}`);
    
    // Get all transcripts for this group to create cumulative conversation
    const allTranscripts = await db.collection("transcripts").find({ 
      group_id: group._id 
    }).sort({ created_at: 1 }).toArray();
    
    // Create cumulative conversation text (chronological order)
    const cumulativeText = allTranscripts.map(t => t.text).join(' ');
    
    // Generate summary of the entire conversation so far
    console.log("ü§ñ Generating summary of full conversation...");
    
    // Get custom prompt for this session
    // Resolve the latest prompt: prefer memory cache, fall back to DB
    let customPrompt = activeSessions.get(sessionCode)?.customPrompt || null;
    if (!customPrompt && session) {
      const promptData = await db.collection("session_prompts").findOne({ session_id: session._id });
      customPrompt = promptData?.prompt || null;
    }
    
    const summary = await summarise(cumulativeText, customPrompt);
    
    // Save/update the summary
    await db.collection("summaries").findOneAndUpdate(
      { group_id: group._id },
      { $set: { text: summary, updated_at: now } },
      { upsert: true }
    );
    
    // Send both new transcription and updated summary to clients
    const roomName = `${sessionCode}-${groupNumber}`;
    io.to(roomName).emit("transcription_and_summary", {
      transcription: {
        text: transcriptionText, // Current chunk only
        cumulativeText: cumulativeText, // Full conversation so far
        words: result.words,
        duration: duration,
        wordCount: wordCount
      },
      summary,
      isLatestSegment: true
    });
    
    // Send update to admin console
    io.to(sessionCode).emit("admin_update", {
      group: groupNumber,
      latestTranscript: transcriptionText,
      cumulativeTranscript: cumulativeText, // Add full conversation for admin
      transcriptDuration: duration,
      transcriptWordCount: wordCount,
      summary,
      stats: {
        totalSegments: allTranscripts.length,
        totalWords: allTranscripts.reduce((sum, t) => sum + (t.word_count || 0), 0),
        totalDuration: allTranscripts.reduce((sum, t) => sum + (t.duration_seconds || 0), 0),
        lastUpdate: now
      }
    });
    }
    
    // Clean up old transcripts to prevent memory issues (keep last 100 per group)
    const allTranscripts = await db.collection("transcripts").find({ 
      group_id: group._id 
    }).sort({ created_at: 1 }).toArray();
    
    if (allTranscripts.length > 100) {
      const oldTranscripts = allTranscripts.slice(0, -100);
      const oldTranscriptIds = oldTranscripts.map(t => t._id);
      
      await db.collection("transcripts").deleteMany({
        _id: { $in: oldTranscriptIds }
      });
      
      console.log(`üßπ Cleaned up ${oldTranscripts.length} old transcripts for group ${groupNumber}`);
    }
    
  } catch (error) {
    console.error(`‚ùå Error processing transcription for group ${groupNumber}:`, error);
    throw error;
  }
}

/* Test mode detection endpoint */
app.post("/api/checkbox/test", express.json(), async (req, res) => {
  try {
    const { sessionCode, transcript } = req.body;
    
    console.log(`üß™ TEST MODE ACTIVATED for session ${sessionCode}`);
    console.log(`üß™ Test transcript length: ${transcript?.length || 0} characters`);
    console.log(`üß™ Test transcript preview: "${transcript?.substring(0, 100)}..."`);
    
    // Forward to regular checkbox processing but with test logging
    const result = await processTestTranscript(sessionCode, transcript);
    
    console.log(`üß™ TEST RESULT: ${result.matches?.length || 0} matches found`);
    if (result.matches?.length > 0) {
      result.matches.forEach((match, index) => {
        console.log(`üß™ Match ${index + 1}: Criteria ${match.criteria_index} - "${match.quote}"`);
      });
    }
    
    res.json(result);
  } catch (err) {
    console.error('üß™ TEST MODE ERROR:', err);
    res.status(500).json({ error: err.message, matches: [], reason: "Test mode error" });
  }
});

async function processTestTranscript(sessionCode, transcript) {
  // Get session info
  const session = await db.collection("sessions").findOne({ code: sessionCode });
  if (!session) {
    throw new Error("Session not found");
  }

  // Get criteria
  const criteria = await db.collection("checkbox_criteria")
    .find({ session_id: session._id })
    .sort({ order_index: 1, created_at: 1 })
    .toArray();

  if (criteria.length === 0) {
    throw new Error("No criteria found for session");
  }

  console.log(`üß™ Processing test transcript against ${criteria.length} criteria`);

  // Get scenario
  const checkboxSession = await db.collection("checkbox_sessions").findOne({ session_id: session._id });
  const scenario = checkboxSession?.scenario || "";

  // Process with AI
  return await processCheckboxTranscript(transcript, criteria, scenario);
}

/* New mindmap-specific chunk transcription endpoint */
app.post("/api/transcribe-mindmap-chunk", upload.single('file'), async (req, res) => {
  const startTime = Date.now();
  
  try {
    const { sessionCode, mode } = req.body;
    const file = req.file;
    
    if (!file || !sessionCode) {
      return res.status(400).json({ 
        success: false, 
        error: 'Missing file or session code' 
      });
    }

    console.log(`üì¶ Received mindmap chunk for transcription`);
    console.log(`üìÅ Processing mindmap chunk: ${file.size} bytes, session: ${sessionCode}`);

    // Get session data
    const session = await db.collection("sessions").findOne({ code: sessionCode });
    if (!session) {
      return res.status(404).json({ 
        success: false, 
        error: 'Session not found' 
      });
    }

    // Transcribe the audio chunk
    console.log(`üéØ Transcribing audio chunk...`);
    const transcriptionResult = await transcribe(file.buffer, file.mimetype);
    
    // Extract transcript text properly
    let transcript = '';
    if (typeof transcriptionResult === 'string') {
      transcript = transcriptionResult;
    } else if (transcriptionResult && transcriptionResult.text) {
      transcript = transcriptionResult.text;
    } else if (transcriptionResult) {
      // Handle other possible formats
      transcript = String(transcriptionResult);
    }
    
    // Ensure we have a valid string
    transcript = String(transcript || '').trim();
    
    if (!transcript || transcript.length === 0) {
      return res.json({
        success: true,
        transcript: '',
        message: 'No speech detected in audio chunk',
        mindmapData: null
      });
    }

    console.log(`üìù Transcription successful: "${transcript}"`);
    
    // Add to transcript history for context
    addToTranscriptHistory(sessionCode, transcript);
    
    // Get contextual transcript (current + previous 2 chunks)
    const contextualTranscript = getContextualTranscript(sessionCode);

    // Get current mindmap state
    const currentMindmapData = await getMindmapData(sessionCode);
    
    let result;
    let mindmapData = null;

    if (!currentMindmapData || !currentMindmapData.children || currentMindmapData.children.length === 0) {
      // Generate initial mindmap with contextual transcript
      console.log(`üß† Generating initial mindmap from transcript...`);
      mindmapData = await generateInitialMindmap(contextualTranscript, session.main_topic);
      
      if (mindmapData) {
        // Store the initial mindmap
        await db.collection("sessions").updateOne(
          { code: sessionCode },
          { 
            $set: { 
              mindmap_data: mindmapData,
              last_updated: new Date()
            }
          }
        );
        
        result = {
          success: true,
          transcript: transcript,
          mindmapData: mindmapData,
          message: `Initial mindmap created with contextual analysis`,
          rawAiResponse: `Generated from ${sessionTranscriptHistory.get(sessionCode)?.length || 1} chunks of context`
        };
      } else {
        // No meaningful content found
        result = {
          success: true,
          transcript: transcript,
          mindmapData: currentMindmapData,
          message: 'No academic content detected in speech',
          filtered: true
        };
      }
    } else {
      // Expand existing mindmap with contextual transcript
      console.log(`üß† Expanding mindmap with contextual speech...`);
      const expansionResult = await expandMindmap(contextualTranscript, currentMindmapData, session.main_topic);
      
      if (!expansionResult.filtered) {
        // Update mindmap in database
        await db.collection("sessions").updateOne(
          { code: sessionCode },
          { 
            $set: { 
              mindmap_data: expansionResult.updatedMindmap,
              last_updated: new Date()
            }
          }
        );
        
        mindmapData = expansionResult.updatedMindmap;
      } else {
        mindmapData = currentMindmapData; // Keep existing mindmap unchanged
      }
      
      result = {
        success: true,
        transcript: transcript,
        mindmapData: mindmapData,
        message: expansionResult.explanation,
        rawAiResponse: expansionResult.rawResponse,
        filtered: expansionResult.filtered
      };
    }

    const processingTime = Date.now() - startTime;
    console.log(`‚úÖ Mindmap chunk processed successfully in ${processingTime}ms`);
    
    res.json(result);

  } catch (error) {
    const processingTime = Date.now() - startTime;
    console.error(`‚ùå Error processing mindmap chunk (${processingTime}ms):`, error);
    
    res.status(500).json({
      success: false,
      error: error.message || 'Failed to process mindmap chunk',
      transcript: '',
      mindmapData: null
    });
  }
});

// Cleanup function for inactive sessions (called on server shutdown)
async function markAllSessionsInactive() {
  try {
    const result = await db.collection("sessions").updateMany(
      { active: true },
      { 
        $set: { 
          active: false, 
          ended_at: new Date() 
        } 
      }
    );
    
    // Clear all transcript histories
    sessionTranscriptHistory.clear();
    console.log("üóëÔ∏è Cleared all transcript histories");
    
    console.log(`üíæ Marked ${result.modifiedCount} sessions as inactive`);
  } catch (error) {
    console.error("‚ùå Error marking sessions inactive:", error);
  }
}

// ... existing code ...

// Enhanced session cleanup
app.delete("/api/sessions/:sessionCode", async (req, res) => {
  try {
    const { sessionCode } = req.params;
    
    // Stop auto-summary if running
    stopAutoSummary(sessionCode);
    
    // Clear transcript history
    clearTranscriptHistory(sessionCode);
    
    // Remove from active sessions
    activeSessions.delete(sessionCode);
    
    // Mark session as inactive in database
    await db.collection("sessions").updateOne(
      { code: sessionCode },
      { 
        $set: { 
          active: false,
          ended_at: new Date()
        }
      }
    );

    res.json({ success: true, message: "Session ended successfully" });
  } catch (error) {
    console.error("‚ùå Error ending session:", error);
    res.status(500).json({ success: false, error: "Failed to end session" });
  }
});

/* ---------- Comprehensive Data Access API ---------- */

/* Get all sessions with comprehensive data across all modes */
app.get("/api/data/sessions", async (req, res) => {
  try {
    const { limit = 20, offset = 0, mode = null } = req.query;
    
    console.log(`üìä Fetching comprehensive session data (limit: ${limit}, offset: ${offset}, mode: ${mode})`);
    
    // Build query filter
    const query = {};
    if (mode && ['summary', 'mindmap', 'checkbox'].includes(mode)) {
      query.mode = mode;
    }
    
    // Get sessions
    const sessions = await db.collection("sessions")
      .find(query)
      .sort({ created_at: -1 })
      .skip(parseInt(offset))
      .limit(parseInt(limit))
      .toArray();
    
    const enrichedSessions = [];
    
    for (const session of sessions) {
      let sessionData = {
        ...session,
        groups: [],
        totalTranscripts: 0,
        totalStudents: 0,
        duration: session.end_time ? session.end_time - session.start_time : null,
        modeSpecificData: null
      };
      
      // Get groups for this session
      const groups = await db.collection("groups")
        .find({ session_id: session._id })
        .sort({ number: 1 })
        .toArray();
      
      for (const group of groups) {
        // Get transcripts for this group
        const transcripts = await db.collection("transcripts")
          .find({ group_id: group._id })
          .sort({ created_at: 1 })
          .toArray();
        
        // Get summary for this group
        const summary = await db.collection("summaries")
          .findOne({ group_id: group._id });
        
        sessionData.groups.push({
          ...group,
          transcriptCount: transcripts.length,
          latestTranscript: transcripts.length > 0 ? transcripts[transcripts.length - 1] : null,
          summary: summary ? summary.content : null,
          summaryTimestamp: summary ? summary.created_at : null
        });
        
        sessionData.totalTranscripts += transcripts.length;
        sessionData.totalStudents += 1; // Each group represents student participation
      }
      
      // Add mode-specific data
      if (session.mode === 'mindmap') {
        const mindmapSession = await db.collection("mindmap_sessions")
          .findOne({ session_id: session._id });
        const mindmapArchive = await db.collection("mindmap_archives")
          .findOne({ session_id: session._id });
        
        sessionData.modeSpecificData = {
          mainTopic: mindmapSession?.main_topic || session.main_topic,
          nodeCount: mindmapArchive?.node_count || 0,
          chatHistory: mindmapSession?.chat_history || [],
          mindmapData: mindmapArchive?.mindmap_data || mindmapSession?.current_mindmap
        };
      } else if (session.mode === 'checkbox') {
        const checkboxSession = await db.collection("checkbox_sessions")
          .findOne({ session_id: session._id });
        const criteria = await db.collection("checkbox_criteria")
          .find({ session_id: session._id })
          .sort({ order_index: 1, created_at: 1 })
          .toArray();
        const progress = await db.collection("checkbox_progress")
          .find({ session_id: session._id })
          .toArray();
        
        const completedCount = progress.filter(p => p.completed).length;
        const totalCriteria = criteria.length;
        
        sessionData.modeSpecificData = {
          scenario: checkboxSession?.scenario || "",
          totalCriteria: totalCriteria,
          completedCriteria: completedCount,
          completionRate: totalCriteria > 0 ? Math.round((completedCount / totalCriteria) * 100) : 0,
          criteria: criteria.map(c => {
            const prog = progress.find(p => p.criteria_id === c._id);
            return {
              description: c.description,
              completed: prog?.completed || false,
              quote: prog?.quote || null,
              completedAt: prog?.completed_at || null
            };
          })
        };
      }
      
      enrichedSessions.push(sessionData);
    }
    
    // Get total count for pagination
    const totalCount = await db.collection("sessions").countDocuments(query);
    
    res.json({
      success: true,
      sessions: enrichedSessions,
      pagination: {
        total: totalCount,
        limit: parseInt(limit),
        offset: parseInt(offset),
        hasMore: parseInt(offset) + parseInt(limit) < totalCount
      },
      summary: {
        totalSessions: totalCount,
        modesAvailable: ['summary', 'mindmap', 'checkbox']
      }
    });
    
  } catch (err) {
    console.error("‚ùå Failed to fetch comprehensive session data:", err);
    res.status(500).json({ error: "Failed to fetch session data" });
  }
});

/* Get detailed data for a specific session */
app.get("/api/data/session/:sessionCode", async (req, res) => {
  try {
    const { sessionCode } = req.params;
    
    console.log(`üìä Fetching detailed data for session: ${sessionCode}`);
    
    // Get session
    const session = await db.collection("sessions").findOne({ code: sessionCode });
    if (!session) {
      return res.status(404).json({ error: "Session not found" });
    }
    
    // Get groups with full transcript data
    const groups = await db.collection("groups")
      .find({ session_id: session._id })
      .sort({ number: 1 })
      .toArray();
    
    const detailedGroups = [];
    for (const group of groups) {
      const transcripts = await db.collection("transcripts")
        .find({ group_id: group._id })
        .sort({ created_at: 1 })
        .toArray();
      
      const summary = await db.collection("summaries")
        .findOne({ group_id: group._id });
      
      detailedGroups.push({
        ...group,
        transcripts: transcripts,
        summary: summary
      });
    }
    
    // Get mode-specific detailed data
    let modeSpecificData = null;
    if (session.mode === 'mindmap') {
      const mindmapSession = await db.collection("mindmap_sessions")
        .findOne({ session_id: session._id });
      const mindmapArchive = await db.collection("mindmap_archives")
        .findOne({ session_id: session._id });
      const logs = await db.collection("session_logs")
        .find({ session_id: session._id })
        .sort({ created_at: 1 })
        .toArray();
      
      modeSpecificData = {
        mindmapSession,
        mindmapArchive,
        processingLogs: logs
      };
    } else if (session.mode === 'checkbox') {
      const checkboxSession = await db.collection("checkbox_sessions")
        .findOne({ session_id: session._id });
      const criteria = await db.collection("checkbox_criteria")
        .find({ session_id: session._id })
        .sort({ order_index: 1, created_at: 1 })
        .toArray();
      const progress = await db.collection("checkbox_progress")
        .find({ session_id: session._id })
        .toArray();
      const logs = await db.collection("session_logs")
        .find({ session_id: session._id })
        .sort({ created_at: 1 })
        .toArray();
      
      modeSpecificData = {
        checkboxSession,
        criteria,
        progress,
        processingLogs: logs
      };
    }
    
    res.json({
      success: true,
      session: session,
      groups: detailedGroups,
      modeSpecificData: modeSpecificData,
      stats: {
        totalGroups: detailedGroups.length,
        totalTranscripts: detailedGroups.reduce((sum, g) => sum + g.transcripts.length, 0),
        duration: session.end_time ? session.end_time - session.start_time : null,
        durationFormatted: session.end_time ? 
          formatDuration(session.end_time - session.start_time) : "In progress"
      }
    });
    
  } catch (err) {
    console.error(`‚ùå Failed to fetch detailed session data for ${req.params.sessionCode}:`, err);
    res.status(500).json({ error: "Failed to fetch session details" });
  }
});

/* Helper function to format duration */
function formatDuration(ms) {
  const seconds = Math.floor(ms / 1000);
  const minutes = Math.floor(seconds / 60);
  const hours = Math.floor(minutes / 60);
  
  if (hours > 0) {
    return `${hours}h ${minutes % 60}m ${seconds % 60}s`;
  } else if (minutes > 0) {
    return `${minutes}m ${seconds % 60}s`;
  } else {
    return `${seconds}s`;
  }
}

// ... existing code ...

/* ---------- Teacher Prompt Management API ---------- */

/* Get all prompts with filtering and search */
app.get("/api/prompts", async (req, res) => {
  try {
    const { 
      search = "", 
      category = "", 
      mode = "", 
      limit = 50, 
      offset = 0,
      sortBy = "created_at",
      sortOrder = "desc"
    } = req.query;
    
    console.log(`üìù Fetching prompts (search: "${search}", category: "${category}", mode: "${mode}")`);
    
    // Build query filter
    const query = {};
    
    if (search.trim()) {
      query.$or = [
        { title: { $regex: search, $options: 'i' } },
        { description: { $regex: search, $options: 'i' } },
        { content: { $regex: search, $options: 'i' } },
        { tags: { $in: [new RegExp(search, 'i')] } }
      ];
    }
    
    if (category) query.category = category;
    if (mode) query.mode = mode;
    
    // Build sort option
    const sortOption = {};
    sortOption[sortBy] = sortOrder === 'desc' ? -1 : 1;
    
    // Get prompts with pagination
    const prompts = await db.collection("teacher_prompts")
      .find(query)
      .sort(sortOption)
      .skip(parseInt(offset))
      .limit(parseInt(limit))
      .toArray();
    
    // Get total count for pagination
    const totalCount = await db.collection("teacher_prompts").countDocuments(query);
    
    // Get categories and modes for filtering
    const categories = await db.collection("teacher_prompts").distinct("category");
    const modes = await db.collection("teacher_prompts").distinct("mode");
    
    res.json({
      success: true,
      prompts: prompts,
      pagination: {
        total: totalCount,
        limit: parseInt(limit),
        offset: parseInt(offset),
        hasMore: parseInt(offset) + parseInt(limit) < totalCount
      },
      filters: {
        categories: categories.sort(),
        modes: modes.sort()
      }
    });
    
  } catch (err) {
    console.error("‚ùå Failed to fetch prompts:", err);
    res.status(500).json({ error: "Failed to fetch prompts" });
  }
});

/* Get a specific prompt by ID */
app.get("/api/prompts/:id", async (req, res) => {
  try {
    const { id } = req.params;
    
    console.log(`üìù Fetching prompt: ${id}`);
    
    const prompt = await db.collection("teacher_prompts").findOne({ _id: id });
    if (!prompt) {
      return res.status(404).json({ error: "Prompt not found" });
    }
    
    // Increment view count
    await db.collection("teacher_prompts").updateOne(
      { _id: id },
      { 
        $inc: { views: 1 },
        $set: { last_viewed: Date.now() }
      }
    );
    
    res.json({
      success: true,
      prompt: prompt
    });
    
  } catch (err) {
    console.error(`‚ùå Failed to fetch prompt ${req.params.id}:`, err);
    res.status(500).json({ error: "Failed to fetch prompt" });
  }
});

/* Create a new prompt */
app.post("/api/prompts", express.json(), async (req, res) => {
  try {
    const { 
      title, 
      description, 
      content, 
      category, 
      mode, 
      tags = [], 
      isPublic = true,
      authorName = "Anonymous Teacher"
    } = req.body;
    
    if (!title || !content) {
      return res.status(400).json({ error: "Title and content are required" });
    }
    
    console.log(`üìù Creating new prompt: "${title}"`);
    
    const promptId = uuid();
    const now = Date.now();
    
    const newPrompt = {
      _id: promptId,
      title: title.trim(),
      description: description ? description.trim() : "",
      content: content.trim(),
      category: category || "General",
      mode: mode || "summary",
      tags: Array.isArray(tags) ? tags.map(tag => tag.trim()).filter(tag => tag.length > 0) : [],
      isPublic: Boolean(isPublic),
      authorName: authorName.trim(),
      created_at: now,
      updated_at: now,
      views: 0,
      last_viewed: null,
      usage_count: 0,
      last_used: null
    };
    
    await db.collection("teacher_prompts").insertOne(newPrompt);
    
    res.json({
      success: true,
      prompt: newPrompt,
      message: "Prompt created successfully"
    });
    
  } catch (err) {
    console.error("‚ùå Failed to create prompt:", err);
    res.status(500).json({ error: "Failed to create prompt" });
  }
});

/* Update an existing prompt */
app.put("/api/prompts/:id", express.json(), async (req, res) => {
  try {
    const { id } = req.params;
    const { 
      title, 
      description, 
      content, 
      category, 
      mode, 
      tags = [], 
      isPublic,
      authorName
    } = req.body;
    
    if (!title || !content) {
      return res.status(400).json({ error: "Title and content are required" });
    }
    
    console.log(`üìù Updating prompt: ${id}`);
    
    const updateData = {
      title: title.trim(),
      description: description ? description.trim() : "",
      content: content.trim(),
      category: category || "General",
      mode: mode || "summary",
      tags: Array.isArray(tags) ? tags.map(tag => tag.trim()).filter(tag => tag.length > 0) : [],
      updated_at: Date.now()
    };
    
    if (typeof isPublic === 'boolean') updateData.isPublic = isPublic;
    if (authorName) updateData.authorName = authorName.trim();
    
    const result = await db.collection("teacher_prompts").updateOne(
      { _id: id },
      { $set: updateData }
    );
    
    if (result.matchedCount === 0) {
      return res.status(404).json({ error: "Prompt not found" });
    }
    
    const updatedPrompt = await db.collection("teacher_prompts").findOne({ _id: id });
    
    res.json({
      success: true,
      prompt: updatedPrompt,
      message: "Prompt updated successfully"
    });
    
  } catch (err) {
    console.error(`‚ùå Failed to update prompt ${req.params.id}:`, err);
    res.status(500).json({ error: "Failed to update prompt" });
  }
});

/* Delete a prompt */
app.delete("/api/prompts/:id", async (req, res) => {
  try {
    const { id } = req.params;
    
    console.log(`üìù Deleting prompt: ${id}`);
    
    const result = await db.collection("teacher_prompts").deleteOne({ _id: id });
    
    if (result.deletedCount === 0) {
      return res.status(404).json({ error: "Prompt not found" });
    }
    
    res.json({
      success: true,
      message: "Prompt deleted successfully"
    });
    
  } catch (err) {
    console.error(`‚ùå Failed to delete prompt ${req.params.id}:`, err);
    res.status(500).json({ error: "Failed to delete prompt" });
  }
});

/* Use/apply a prompt (increments usage counter) */
app.post("/api/prompts/:id/use", express.json(), async (req, res) => {
  try {
    const { id } = req.params;
    const { sessionCode } = req.body;
    
    console.log(`üìù Using prompt ${id} for session ${sessionCode}`);
    
    const prompt = await db.collection("teacher_prompts").findOne({ _id: id });
    if (!prompt) {
      return res.status(404).json({ error: "Prompt not found" });
    }
    
    // Increment usage counter
    await db.collection("teacher_prompts").updateOne(
      { _id: id },
      { 
        $inc: { usage_count: 1 },
        $set: { last_used: Date.now() }
      }
    );
    
    res.json({
      success: true,
      prompt: prompt,
      message: "Prompt applied successfully"
    });
    
  } catch (err) {
    console.error(`‚ùå Failed to use prompt ${req.params.id}:`, err);
    res.status(500).json({ error: "Failed to use prompt" });
  }
});

/* Get prompt statistics */
app.get("/api/prompts/stats/overview", async (req, res) => {
  try {
    console.log("üìä Fetching prompt statistics");
    
    const totalPrompts = await db.collection("teacher_prompts").countDocuments();
    const publicPrompts = await db.collection("teacher_prompts").countDocuments({ isPublic: true });
    const privatePrompts = totalPrompts - publicPrompts;
    
    // Most popular prompts
    const popularPrompts = await db.collection("teacher_prompts")
      .find({ isPublic: true })
      .sort({ usage_count: -1, views: -1 })
      .limit(5)
      .toArray();
    
    // Recent prompts
    const recentPrompts = await db.collection("teacher_prompts")
      .find({ isPublic: true })
      .sort({ created_at: -1 })
      .limit(5)
      .toArray();
    
    // Category distribution
    const categoryStats = await db.collection("teacher_prompts").aggregate([
      { $group: { _id: "$category", count: { $sum: 1 } } },
      { $sort: { count: -1 } }
    ]).toArray();
    
    // Mode distribution
    const modeStats = await db.collection("teacher_prompts").aggregate([
      { _id: "$mode", count: { $sum: 1 } },
      { $sort: { count: -1 } }
    ]).toArray();
    
    res.json({
      success: true,
      stats: {
        totalPrompts,
        publicPrompts,
        privatePrompts,
        popularPrompts,
        recentPrompts,
        categoryDistribution: categoryStats,
        modeDistribution: modeStats
      }
    });
    
  } catch (err) {
    console.error("‚ùå Failed to fetch prompt statistics:", err);
    res.status(500).json({ error: "Failed to fetch statistics" });
  }
});

/* Duplicate/clone a prompt */
app.post("/api/prompts/:id/clone", express.json(), async (req, res) => {
  try {
    const { id } = req.params;
    const { authorName = "Anonymous Teacher" } = req.body;
    
    console.log(`üìù Cloning prompt: ${id}`);
    
    const originalPrompt = await db.collection("teacher_prompts").findOne({ _id: id });
    if (!originalPrompt) {
      return res.status(404).json({ error: "Prompt not found" });
    }
    
    const clonedPromptId = uuid();
    const now = Date.now();
    
    const clonedPrompt = {
      ...originalPrompt,
      _id: clonedPromptId,
      title: `${originalPrompt.title} (Copy)`,
      authorName: authorName.trim(),
      created_at: now,
      updated_at: now,
      views: 0,
      last_viewed: null,
      usage_count: 0,
      last_used: null,
      isPublic: false // Clones start as private
    };
    
    await db.collection("teacher_prompts").insertOne(clonedPrompt);
    
    res.json({
      success: true,
      prompt: clonedPrompt,
      message: "Prompt cloned successfully"
    });
    
  } catch (err) {
    console.error(`‚ùå Failed to clone prompt ${req.params.id}:`, err);
    res.status(500).json({ error: "Failed to clone prompt" });
  }
});

// ... existing code ...

/* Seed default prompts for teachers */
async function seedDefaultPrompts() {
  try {
    console.log('üå± Checking for default prompts...');
    
    const existingPrompts = await db.collection("teacher_prompts").countDocuments();
    if (existingPrompts > 0) {
      console.log('üå± Default prompts already exist, skipping seed');
      return;
    }
    
    console.log('üå± Seeding default teacher prompts...');
    
    const defaultPrompts = [
      {
        _id: uuid(),
        title: "Science Discussion Summary",
        description: "Summarizes science classroom discussions with focus on key concepts, student understanding, and misconceptions",
        content: `Please analyze this classroom discussion transcript and create a comprehensive summary focusing on:

1. **Key Scientific Concepts Discussed**: What main scientific ideas, theories, or principles were covered?

2. **Student Understanding**: What evidence shows students are grasping the concepts? Quote specific student responses.

3. **Misconceptions Identified**: What incorrect ideas or misunderstandings did students express? How were they addressed?

4. **Questions & Inquiry**: What questions did students ask? What sparked their curiosity?

5. **Practical Applications**: Did students connect the science to real-world examples or applications?

6. **Next Steps**: Based on this discussion, what topics might need more explanation or what should be covered next?

Format your response clearly with these sections. Include specific quotes from students to support your analysis.

Transcript: {transcript}`,
        category: "Science",
        mode: "summary",
        tags: ["science", "discussion", "analysis", "misconceptions"],
        isPublic: true,
        authorName: "Smart Classroom Team",
        created_at: Date.now(),
        updated_at: Date.now(),
        views: 0,
        last_viewed: null,
        usage_count: 0,
        last_used: null
      },
      {
        _id: uuid(),
        title: "Mathematics Problem-Solving Analysis",
        description: "Analyzes math discussions focusing on problem-solving strategies, reasoning, and mathematical communication",
        content: `Analyze this mathematics classroom discussion and provide insights on:

1. **Problem-Solving Strategies**: What approaches did students use? Were they effective?

2. **Mathematical Reasoning**: How did students explain their thinking? What reasoning patterns emerged?

3. **Collaboration & Communication**: How well did students explain their ideas to peers? What mathematical vocabulary was used?

4. **Errors & Learning**: What mistakes were made and how were they corrected? What learning opportunities arose from errors?

5. **Conceptual Understanding**: Do students understand the underlying mathematical concepts or just procedures?

6. **Differentiation Needs**: Which students may need additional support or challenge?

Include specific examples from the transcript to illustrate your points.

Transcript: {transcript}`,
        category: "Mathematics",
        mode: "summary",
        tags: ["mathematics", "problem-solving", "reasoning", "communication"],
        isPublic: true,
        authorName: "Smart Classroom Team",
        created_at: Date.now(),
        updated_at: Date.now(),
        views: 0,
        last_viewed: null,
        usage_count: 0,
        last_used: null
      },
      {
        _id: uuid(),
        title: "Literature Discussion Mindmap",
        description: "Creates a mindmap of literature discussions showing themes, character analysis, and literary devices",
        content: `Create a structured mindmap from this literature discussion focusing on:

Main Topic: {topic}

Organize the discussion into these main branches:
- Character Analysis (motivations, development, relationships)
- Themes & Messages (central ideas, author's purpose)
- Literary Devices (symbolism, metaphors, imagery, etc.)
- Plot & Structure (events, conflicts, resolution)
- Student Interpretations (different viewpoints, personal connections)
- Questions & Wonderings (unresolved questions, areas for further discussion)

For each branch, identify 2-4 specific points from the discussion. Include brief quotes or paraphrases from students when relevant.

Create clear, concise nodes that capture the essence of student thinking and literary analysis.

Transcript: {transcript}`,
        category: "Language Arts",
        mode: "mindmap",
        tags: ["literature", "analysis", "themes", "characters"],
        isPublic: true,
        authorName: "Smart Classroom Team",
        created_at: Date.now(),
        updated_at: Date.now(),
        views: 0,
        last_viewed: null,
        usage_count: 0,
        last_used: null
      },
      {
        _id: uuid(),
        title: "Social Studies Debate Assessment",
        description: "Evaluates student participation in social studies debates using specific criteria",
        content: `Evaluate this social studies discussion/debate based on the following criteria. Mark each as completed when there is clear evidence in the transcript:

Students demonstrate understanding of historical context
Students use evidence from primary or secondary sources
Students present multiple perspectives on the issue
Students make connections to current events or modern parallels
Students use appropriate historical vocabulary
Students listen respectfully to opposing viewpoints
Students ask thoughtful follow-up questions
Students support their arguments with specific examples
Students acknowledge counterarguments
Students demonstrate critical thinking about sources and bias

For each completed criteria, provide a specific quote from the transcript that demonstrates the skill.

Focus on identifying clear evidence of these historical thinking skills in student responses.`,
        category: "Social Studies",
        mode: "checkbox",
        tags: ["debate", "historical thinking", "evidence", "perspectives"],
        isPublic: true,
        authorName: "Smart Classroom Team",
        created_at: Date.now(),
        updated_at: Date.now(),
        views: 0,
        last_viewed: null,
        usage_count: 0,
        last_used: null
      },
      {
        _id: uuid(),
        title: "General Discussion Facilitation",
        description: "Analyzes any classroom discussion for participation patterns, engagement, and facilitation opportunities",
        content: `Analyze this classroom discussion for facilitation insights:

**Participation Analysis:**
- Who contributed most/least to the discussion?
- What types of contributions were made (questions, answers, building on ideas, etc.)?
- Were there opportunities for more students to participate?

**Discussion Quality:**
- What evidence shows deep thinking vs. surface-level responses?
- How well did students build on each other's ideas?
- What questions or comments moved the discussion forward?

**Teacher Facilitation:**
- What teacher moves were effective in promoting discussion?
- Where could different questioning or facilitation strategies have been helpful?
- What opportunities for student-led discussion emerged?

**Engagement Indicators:**
- What showed students were actively listening and engaged?
- Were there moments of excitement, confusion, or breakthrough understanding?

**Next Steps:**
- What follow-up questions or activities would extend this discussion?
- Which students might benefit from individual check-ins?

Transcript: {transcript}`,
        category: "General",
        mode: "summary",
        tags: ["facilitation", "participation", "engagement", "discussion"],
        isPublic: true,
        authorName: "Smart Classroom Team",
        created_at: Date.now(),
        updated_at: Date.now(),
        views: 0,
        last_viewed: null,
        usage_count: 0,
        last_used: null
      },
      {
        _id: uuid(),
        title: "Project-Based Learning Assessment",
        description: "Evaluates collaborative project discussions for 21st-century skills and learning outcomes",
        content: `Assess this project-based learning discussion using these criteria. Mark completed when evidence is present:

Students identify and define the problem clearly
Students brainstorm multiple solution approaches
Students assign roles and responsibilities effectively
Students demonstrate research and information literacy skills
Students show creativity and innovation in their ideas
Students communicate ideas clearly to team members
Students listen actively and build on others' contributions
Students show persistence when facing challenges
Students reflect on their learning process
Students make connections to real-world applications
Students demonstrate digital literacy or technology integration
Students show cultural awareness or global perspective
Students exhibit leadership skills
Students practice time management and organization
Students engage in constructive peer feedback

Provide specific quotes that demonstrate each completed criterion.`,
        category: "Assessment",
        mode: "checkbox",
        tags: ["project-based", "collaboration", "21st-century-skills", "assessment"],
        isPublic: true,
        authorName: "Smart Classroom Team",
        created_at: Date.now(),
        updated_at: Date.now(),
        views: 0,
        last_viewed: null,
        usage_count: 0,
        last_used: null
      }
    ];
    
    await db.collection("teacher_prompts").insertMany(defaultPrompts);
    console.log(`üå± Successfully seeded ${defaultPrompts.length} default prompts`);
    
  } catch (err) {
    console.error('‚ùå Failed to seed default prompts:', err);
  }
}

// ... existing code ...

// Clean up old session data to prevent contamination
async function cleanupOldSessionData(sessionCode) {
  try {
    console.log(`üßπ Cleaning up old data for session: ${sessionCode}`);
    
    // Get the session document
    const session = await db.collection("sessions").findOne({ code: sessionCode });
    if (!session) {
      console.log(`üìã No session found with code: ${sessionCode}`);
      return;
    }
    
    // Delete old checkbox progress
    const progressResult = await db.collection("checkbox_progress").deleteMany({ session_id: session._id });
    console.log(`üóëÔ∏è Deleted ${progressResult.deletedCount} old progress records`);
    
    // Delete old checkbox criteria
    const criteriaResult = await db.collection("checkbox_criteria").deleteMany({ session_id: session._id });
    console.log(`üóëÔ∏è Deleted ${criteriaResult.deletedCount} old criteria records`);
    
    // Delete old checkbox session
    const sessionResult = await db.collection("checkbox_sessions").deleteMany({ session_id: session._id });
    console.log(`üóëÔ∏è Deleted ${sessionResult.deletedCount} old checkbox session records`);
    
    console.log(`‚úÖ Session ${sessionCode} cleaned up successfully`);
  } catch (err) {
    console.error(`‚ùå Error cleaning up session ${sessionCode}:`, err);
  }
}
